{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Hybrid CNN+MLP Training (V4.3 Enhanced) with Context Windows - oː/ɔ Phoneme Pair\n",
    "\n",
    "**Enhanced version** with Focal Loss, SpecAugment, and improved architecture:\n",
    "\n",
    "**Key improvements in V4.3:**\n",
    "1. **Focal Loss**: Replaces LabelSmoothingCrossEntropy to focus on hard examples (70%+ high-confidence errors)\n",
    "2. **SpecAugment**: Frequency and time masking for spectrogram augmentation during training\n",
    "3. **Enhanced Architecture**:\n",
    "   - Multi-head attention in cross-attention fusion (with dropout)\n",
    "   - Residual connections in MLP branch\n",
    "   - Enhanced SE blocks in CNN branch\n",
    "4. **Code improvements**:\n",
    "   - Fixed file loading duplication\n",
    "   - Optimized data loading and processing\n",
    "   - Added error handling and validation\n",
    "   - Improved reproducibility with seed setting\n",
    "   - Vectorized operations for better performance\n",
    "   - **Modular code structure**: Common classes and functions imported from `hybrid_model_utils.py`\n",
    "\n",
    "**Expected improvements:**\n",
    "- Better handling of hard examples (Focal Loss)\n",
    "- Improved generalization (SpecAugment)\n",
    "- Better feature fusion (Multi-head attention with dropout)\n",
    "- More stable training (Residual connections)\n",
    "- Better code quality and maintainability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 23:06:26,760 - INFO - Random seed set to 42 for reproducibility\n",
      "2026-01-06 23:06:26,771 - INFO - Using MPS device\n",
      "2026-01-06 23:06:26,771 - INFO - Data directory: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2\n",
      "2026-01-06 23:06:26,772 - INFO - Features directory: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2/features\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import common utilities from shared module\n",
    "from hybrid_model_utils import (\n",
    "    set_seed,\n",
    "    SpecAugment,\n",
    "    HybridDataset,\n",
    "    HybridCNNMLP_V4_3,\n",
    "    FocalLoss,\n",
    "    WarmupCosineScheduler,\n",
    "    train_epoch,\n",
    "    validate,\n",
    "    train_model,\n",
    "    evaluate_model\n",
    ")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "logger.info(\"Random seed set to 42 for reproducibility\")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'specaugment': {\n",
    "        'F': 27,\n",
    "        'T': 40,\n",
    "        'm_F': 2,\n",
    "        'm_T': 2\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 200,\n",
    "        'warmup_epochs': 5,\n",
    "        'initial_lr': 5e-4,\n",
    "        'min_lr': 1e-6,\n",
    "        'weight_decay': 1e-4,\n",
    "        'dropout': 0.4,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'early_stopping_patience': 10\n",
    "    },\n",
    "    'focal_loss': {\n",
    "        'alpha': 0.25,\n",
    "        'gamma': 2.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Project root\n",
    "# Determine project root (parent of notebooks directory)\nPROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "\n",
    "# Data directory (with context v2 - includes VOT, burst features)\n",
    "DATA_DIR = PROJECT_ROOT / 'artifacts' / 'oː-ɔ_dl_models_with_context_v2'\n",
    "FEATURES_DIR = DATA_DIR / 'features'\n",
    "\n",
    "# Validate directories exist\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n",
    "if not FEATURES_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Features directory not found: {FEATURES_DIR}\")\n",
    "\n",
    "# Device setup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    logger.info(\"Using MPS device\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    logger.info(\"Using CUDA device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    logger.info(\"Using CPU device\")\n",
    "\n",
    "logger.info(f\"Data directory: {DATA_DIR}\")\n",
    "logger.info(f\"Features directory: {FEATURES_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with Context Windows (V2 - with VOT and Burst Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/SSanDisk/SpeechRec-German/venv_pytorch/lib/python3.11/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2026-01-06 23:06:27,126 - INFO - Dataset shape: (36820, 134)\n",
      "2026-01-06 23:06:27,126 - INFO - Feature columns (loaded): 130\n",
      "2026-01-06 23:06:27,130 - WARNING - 1 feature columns are missing from DataFrame\n",
      "2026-01-06 23:06:27,131 - WARNING - Missing columns: ['duration_ms_features']...\n",
      "2026-01-06 23:06:27,131 - INFO - Note: 'duration_ms_features' is missing - this is expected if duration_ms wasn't duplicated during merge.\n",
      "2026-01-06 23:06:27,131 - INFO -       This column is not a real feature and can be safely ignored.\n",
      "2026-01-06 23:06:27,132 - INFO - Feature columns (filtered): 129\n",
      "2026-01-06 23:06:27,132 - WARNING - Feature count mismatch. Scaler expects 130 features, but we have 129\n",
      "2026-01-06 23:06:27,132 - INFO - This is OK if some features were removed from the dataset. The scaler will be retrained on available features.\n",
      "2026-01-06 23:06:27,133 - INFO - Metadata columns present: ['phoneme_id', 'class', 'duration_ms']\n",
      "2026-01-06 23:06:27,139 - INFO - Class encoding: {'oː': np.int64(0), 'ɔ': np.int64(1)}\n",
      "2026-01-06 23:06:27,144 - INFO - Class distribution:\n",
      "class\n",
      "ɔ     23700\n",
      "oː    13120\n",
      "Name: count, dtype: int64\n",
      "2026-01-06 23:06:27,155 - INFO - Split distribution:\n",
      "split\n",
      "train    25788\n",
      "test      5523\n",
      "val       5509\n",
      "Name: count, dtype: int64\n",
      "Loading spectrograms: 100%|██████████| 36820/36820 [00:02<00:00, 15694.68it/s]\n",
      "2026-01-06 23:06:31,709 - INFO - Loaded 36,820 spectrograms\n",
      "2026-01-06 23:06:31,710 - INFO - Spectrogram shape: (128, 7)\n",
      "2026-01-06 23:06:31,730 - INFO - Dataset after filtering for spectrograms: 36820 samples\n"
     ]
    }
   ],
   "source": [
    "# Load feature columns\n",
    "feature_cols_path = DATA_DIR / 'feature_cols.json'\n",
    "if not feature_cols_path.exists():\n",
    "    raise FileNotFoundError(f\"Feature columns file not found: {feature_cols_path}\")\n",
    "with open(feature_cols_path, 'r') as f:\n",
    "    feature_cols = json.load(f)\n",
    "\n",
    "# Load feature scaler\n",
    "scaler_path = DATA_DIR / 'feature_scaler.joblib'\n",
    "if not scaler_path.exists():\n",
    "    raise FileNotFoundError(f\"Scaler file not found: {scaler_path}\")\n",
    "feature_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Load class weights\n",
    "class_weights_path = DATA_DIR / 'class_weights.json'\n",
    "if not class_weights_path.exists():\n",
    "    raise FileNotFoundError(f\"Class weights file not found: {class_weights_path}\")\n",
    "with open(class_weights_path, 'r') as f:\n",
    "    class_weights_dict = json.load(f)\n",
    "\n",
    "# Load features DataFrame (from 02.2 - includes VOT, burst features)\n",
    "features_path = FEATURES_DIR / 'features.parquet'\n",
    "if not features_path.exists():\n",
    "    raise FileNotFoundError(f\"Features file not found: {features_path}\")\n",
    "df = pd.read_parquet(features_path)\n",
    "logger.info(f\"Dataset shape: {df.shape}\")\n",
    "logger.info(f\"Feature columns (loaded): {len(feature_cols)}\")\n",
    "\n",
    "# Filter feature_cols to only include columns that exist in DataFrame\n",
    "original_feature_cols = feature_cols.copy()  # Save original before filtering\n",
    "original_feature_count = len(feature_cols)\n",
    "feature_cols = [col for col in feature_cols if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "if len(feature_cols) != original_feature_count:\n",
    "    missing_cols = set(original_feature_cols) - set(feature_cols)\n",
    "    logger.warning(f\"{original_feature_count - len(feature_cols)} feature columns are missing from DataFrame\")\n",
    "    if missing_cols:\n",
    "        logger.warning(f\"Missing columns: {list(missing_cols)[:10]}...\")\n",
    "        \n",
    "    if 'duration_ms_features' in missing_cols:\n",
    "        logger.info(\"Note: 'duration_ms_features' is missing - this is expected if duration_ms wasn't duplicated during merge.\")\n",
    "        logger.info(\"      This column is not a real feature and can be safely ignored.\")\n",
    "\n",
    "logger.info(f\"Feature columns (filtered): {len(feature_cols)}\")\n",
    "\n",
    "# Verify feature count matches scaler\n",
    "if hasattr(feature_scaler, 'n_features_in_'):\n",
    "    if len(feature_cols) != feature_scaler.n_features_in_:\n",
    "        logger.warning(f\"Feature count mismatch. Scaler expects {feature_scaler.n_features_in_} features, but we have {len(feature_cols)}\")\n",
    "        logger.info(\"This is OK if some features were removed from the dataset. The scaler will be retrained on available features.\")\n",
    "\n",
    "# Check what metadata columns we have\n",
    "metadata_cols = ['phoneme_id', 'class', 'duration_ms', 'phoneme', 'utterance_id']\n",
    "present_metadata = [col for col in metadata_cols if col in df.columns]\n",
    "logger.info(f\"Metadata columns present: {present_metadata}\")\n",
    "\n",
    "# Handle class column\n",
    "if 'class' not in df.columns:\n",
    "    if 'phoneme' in df.columns:\n",
    "        df['class'] = df['phoneme']\n",
    "        logger.info(\"Created 'class' column from 'phoneme'\")\n",
    "    else:\n",
    "        raise ValueError(\"Neither 'class' nor 'phoneme' column found in features.parquet.\")\n",
    "\n",
    "# Filter to only oː and ɔ classes\n",
    "if not df['class'].isin(['oː', 'ɔ']).all():\n",
    "    df = df[df['class'].isin(['oː', 'ɔ'])].copy()\n",
    "    logger.info(f\"Dataset after filtering to oː/ɔ: {len(df)} samples\")\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df['class_encoded'] = le.fit_transform(df['class'])  # oː=0, ɔ=1\n",
    "class_encoding = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "logger.info(f\"Class encoding: {class_encoding}\")\n",
    "logger.info(f\"Class distribution:\\n{df['class'].value_counts()}\")\n",
    "\n",
    "# Load split indices\n",
    "split_indices_path = DATA_DIR / 'split_indices.json'\n",
    "if not split_indices_path.exists():\n",
    "    raise FileNotFoundError(f\"Split indices file not found: {split_indices_path}\")\n",
    "with open(split_indices_path, 'r') as f:\n",
    "    split_indices = json.load(f)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create split column based on indices\n",
    "df['split'] = 'train'\n",
    "if len(df) > max(split_indices['val'] + split_indices['test']):\n",
    "    df.loc[split_indices['val'], 'split'] = 'val'\n",
    "    df.loc[split_indices['test'], 'split'] = 'test'\n",
    "else:\n",
    "    logger.warning(\"Split indices may not match DataFrame indices. Using phoneme_id matching...\")\n",
    "    val_ids = set(df.loc[split_indices['val'], 'phoneme_id'].values) if len(df) > max(split_indices['val']) else set()\n",
    "    test_ids = set(df.loc[split_indices['test'], 'phoneme_id'].values) if len(df) > max(split_indices['test']) else set()\n",
    "    df.loc[df['phoneme_id'].isin(val_ids), 'split'] = 'val'\n",
    "    df.loc[df['phoneme_id'].isin(test_ids), 'split'] = 'test'\n",
    "\n",
    "logger.info(f\"Split distribution:\\n{df['split'].value_counts()}\")\n",
    "\n",
    "# Load spectrograms with error handling\n",
    "spectrograms_path = FEATURES_DIR / 'spectrograms.h5'\n",
    "if not spectrograms_path.exists():\n",
    "    raise FileNotFoundError(f\"Spectrograms file not found: {spectrograms_path}\")\n",
    "\n",
    "spectrograms_dict = {}\n",
    "try:\n",
    "    with h5py.File(spectrograms_path, 'r') as f:\n",
    "        phoneme_ids = list(f.keys())\n",
    "        for phoneme_id in tqdm(phoneme_ids, desc=\"Loading spectrograms\"):\n",
    "            try:\n",
    "                spectrograms_dict[phoneme_id] = f[phoneme_id][:]\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to load spectrogram for {phoneme_id}: {e}\")\n",
    "                continue\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load spectrograms: {e}\")\n",
    "\n",
    "logger.info(f\"Loaded {len(spectrograms_dict):,} spectrograms\")\n",
    "if spectrograms_dict:\n",
    "    sample_shape = list(spectrograms_dict.values())[0].shape\n",
    "    logger.info(f\"Spectrogram shape: {sample_shape}\")\n",
    "\n",
    "# Filter to only phonemes with spectrograms\n",
    "df['phoneme_id_str'] = df['phoneme_id'].astype(str)\n",
    "df['has_spectrogram'] = df['phoneme_id_str'].isin(spectrograms_dict.keys())\n",
    "df = df[df['has_spectrogram']].copy()\n",
    "logger.info(f\"Dataset after filtering for spectrograms: {len(df)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Classes with SpecAugment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 23:06:31,751 - INFO - Feature count mismatch detected: 129 features in DataFrame vs 130 in scaler\n",
      "2026-01-06 23:06:31,751 - INFO - Retraining scaler on train split with current features...\n",
      "2026-01-06 23:06:31,865 - INFO - Scaler retrained on 129 features\n",
      "2026-01-06 23:06:32,024 - INFO - Train dataset: 25788 samples (with SpecAugment)\n",
      "2026-01-06 23:06:32,024 - INFO - Val dataset: 5509 samples\n",
      "2026-01-06 23:06:32,024 - INFO - Test dataset: 5523 samples\n",
      "2026-01-06 23:06:32,025 - INFO - \n",
      "Class distribution in training set:\n",
      "2026-01-06 23:06:32,025 - INFO -   ɔ: 16643 samples (64.5%)\n",
      "2026-01-06 23:06:32,026 - INFO -   oː: 9145 samples (35.5%)\n",
      "2026-01-06 23:06:32,026 - INFO - Imbalance ratio: 45.1% (threshold: 25.0%)\n",
      "2026-01-06 23:06:32,026 - INFO - Significant class imbalance detected (45.1% > 25.0%), applying class balancing\n",
      "2026-01-06 23:06:32,033 - INFO - Using WeightedRandomSampler with class weights: {'oː': np.float64(1.4031994776363044), 'ɔ': np.float64(0.7767937827579975)}\n",
      "2026-01-06 23:06:32,033 - INFO - Train batches: 403\n",
      "2026-01-06 23:06:32,034 - INFO - Val batches: 87\n",
      "2026-01-06 23:06:32,034 - INFO - Test batches: 87\n",
      "2026-01-06 23:06:32,070 - INFO - Sample batch - Spectrogram shape: torch.Size([64, 1, 128, 7]), Features shape: torch.Size([64, 129]), Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Check and retrain scaler if needed\n",
    "\n",
    "train_df = df[df['split'] == 'train'].reset_index(drop=True)\n",
    "\n",
    "train_feature_cols = [col for col in feature_cols if col in train_df.columns and pd.api.types.is_numeric_dtype(train_df[col])]\n",
    "\n",
    "feature_cols = train_feature_cols\n",
    "\n",
    "\n",
    "\n",
    "if hasattr(feature_scaler, 'n_features_in_') and len(feature_cols) != feature_scaler.n_features_in_:\n",
    "\n",
    "    logger.info(f\"Feature count mismatch detected: {len(feature_cols)} features in DataFrame vs {feature_scaler.n_features_in_} in scaler\")\n",
    "\n",
    "    logger.info(\"Retraining scaler on train split with current features...\")\n",
    "\n",
    "    X_train_features = train_df[feature_cols].values.astype(np.float32)\n",
    "\n",
    "    X_train_features = np.nan_to_num(X_train_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "\n",
    "    feature_scaler.fit(X_train_features)\n",
    "\n",
    "    logger.info(f\"Scaler retrained on {len(feature_cols)} features\")\n",
    "\n",
    "else:\n",
    "\n",
    "    logger.info(f\"Using existing scaler with {feature_scaler.n_features_in_} features\")\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets with SpecAugment for training\n",
    "\n",
    "train_hybrid_ds = HybridDataset(\n",
    "\n",
    "    df, spectrograms_dict, feature_cols, \n",
    "\n",
    "    scaler=feature_scaler, split='train', \n",
    "\n",
    "    use_specaugment=True, \n",
    "\n",
    "    specaug_config=CONFIG['specaugment']\n",
    "\n",
    ")\n",
    "\n",
    "val_hybrid_ds = HybridDataset(\n",
    "\n",
    "    df, spectrograms_dict, feature_cols, \n",
    "\n",
    "    scaler=feature_scaler, split='val', \n",
    "\n",
    "    use_specaugment=False\n",
    "\n",
    ")\n",
    "\n",
    "test_hybrid_ds = HybridDataset(\n",
    "\n",
    "    df, spectrograms_dict, feature_cols, \n",
    "\n",
    "    scaler=feature_scaler, split='test', \n",
    "\n",
    "    use_specaugment=False\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"Train dataset: {len(train_hybrid_ds)} samples (with SpecAugment)\")\n",
    "\n",
    "logger.info(f\"Val dataset: {len(val_hybrid_ds)} samples\")\n",
    "\n",
    "logger.info(f\"Test dataset: {len(test_hybrid_ds)} samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Check class imbalance and decide whether to apply balancing\n",
    "\n",
    "IMBALANCE_THRESHOLD = 0.25  # 25% imbalance threshold\n",
    "\n",
    "train_class_counts = train_df['class'].value_counts()\n",
    "\n",
    "min_count = train_class_counts.min()\n",
    "\n",
    "max_count = train_class_counts.max()\n",
    "\n",
    "imbalance_ratio = 1.0 - (min_count / max_count)\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"\\nClass distribution in training set:\")\n",
    "\n",
    "for cls, count in train_class_counts.items():\n",
    "\n",
    "    logger.info(f\"  {cls}: {count} samples ({count/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "logger.info(f\"Imbalance ratio: {imbalance_ratio:.1%} (threshold: {IMBALANCE_THRESHOLD:.1%})\")\n",
    "\n",
    "\n",
    "\n",
    "if imbalance_ratio > IMBALANCE_THRESHOLD:\n",
    "\n",
    "    # Apply balancing for significant imbalance\n",
    "\n",
    "    logger.info(f\"Significant class imbalance detected ({imbalance_ratio:.1%} > {IMBALANCE_THRESHOLD:.1%}), applying class balancing\")\n",
    "\n",
    "    use_class_balancing = True\n",
    "\n",
    "    # Use class weights from file (computed with 'balanced' strategy)\n",
    "\n",
    "    class_weights_array = np.array([class_weights_dict.get(str(i), class_weights_dict.get(i, 1.0)) for i in range(2)])\n",
    "\n",
    "else:\n",
    "\n",
    "    # Skip balancing for balanced or slightly imbalanced classes\n",
    "\n",
    "    logger.info(f\"Classes are balanced or slightly imbalanced ({imbalance_ratio:.1%} <= {IMBALANCE_THRESHOLD:.1%}), skipping class balancing\")\n",
    "\n",
    "    use_class_balancing = False\n",
    "\n",
    "    # Use equal weights\n",
    "\n",
    "    class_weights_array = np.array([1.0, 1.0])\n",
    "\n",
    "\n",
    "\n",
    "# Create sampler based on imbalance check\n",
    "\n",
    "train_labels = df[df['split'] == 'train']['class_encoded'].values\n",
    "\n",
    "if use_class_balancing:\n",
    "\n",
    "    sample_weights = np.array([class_weights_array[label] for label in train_labels])\n",
    "\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    logger.info(f\"Using WeightedRandomSampler with class weights: {dict(zip(le.classes_, class_weights_array))}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    sampler = None  # Will use shuffle=True instead\n",
    "\n",
    "    logger.info(\"Using standard DataLoader with shuffle=True (no class balancing)\")\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "\n",
    "BATCH_SIZE = CONFIG['training']['batch_size']\n",
    "\n",
    "if sampler is not None:\n",
    "    train_hybrid_loader = DataLoader(train_hybrid_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
    "else:\n",
    "    train_hybrid_loader = DataLoader(train_hybrid_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "val_hybrid_loader = DataLoader(val_hybrid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_hybrid_loader = DataLoader(test_hybrid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"Train batches: {len(train_hybrid_loader)}\")\n",
    "\n",
    "logger.info(f\"Val batches: {len(val_hybrid_loader)}\")\n",
    "\n",
    "logger.info(f\"Test batches: {len(test_hybrid_loader)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Test a batch\n",
    "\n",
    "sample_batch = next(iter(train_hybrid_loader))\n",
    "\n",
    "logger.info(f\"Sample batch - Spectrogram shape: {sample_batch[0][0].shape}, Features shape: {sample_batch[0][1].shape}, Labels shape: {sample_batch[1].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 23:06:32,140 - INFO - Model: HybridCNNMLP_V4_3\n",
      "2026-01-06 23:06:32,140 - INFO - Total parameters: 6,579,554\n",
      "2026-01-06 23:06:32,141 - INFO - Trainable parameters: 6,579,554\n",
      "2026-01-06 23:06:32,141 - INFO - Number of features: 129\n",
      "2026-01-06 23:06:32,835 - INFO - \n",
      "Training configuration:\n",
      "2026-01-06 23:06:32,835 - INFO - - Epochs: 200\n",
      "2026-01-06 23:06:32,835 - INFO - - Warmup epochs: 5\n",
      "2026-01-06 23:06:32,836 - INFO - - Initial LR: 0.0005\n",
      "2026-01-06 23:06:32,836 - INFO - - Loss function: Focal Loss (alpha=0.25, gamma=2.0)\n",
      "2026-01-06 23:06:32,836 - INFO - - Gradient clipping: 1.0\n",
      "2026-01-06 23:06:32,836 - INFO - - Early stopping patience: 10\n",
      "2026-01-06 23:06:32,836 - INFO - - Dropout: 0.4\n",
      "2026-01-06 23:06:32,836 - INFO - - SpecAugment: Enabled for training\n",
      "2026-01-06 23:06:32,836 - INFO - - Context windows: ±100ms (V2 with VOT and burst features)\n",
      "2026-01-06 23:06:32,837 - INFO - - Save directory: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2/improved_models/hybrid_cnn_mlp_v4_3_enhanced\n"
     ]
    }
   ],
   "source": [
    "# Create model V4.3 with automatic feature count detection\n",
    "\n",
    "model = HybridCNNMLP_V4_3(\n",
    "\n",
    "    n_features=len(feature_cols), \n",
    "\n",
    "    num_classes=2, \n",
    "\n",
    "    dropout=CONFIG['training']['dropout']\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Print model info\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "logger.info(f\"Model: {model.get_config()['model_type']}\")\n",
    "\n",
    "logger.info(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "logger.info(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "logger.info(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Prepare class weights for loss function\n",
    "# Prepare class weights for loss function (use computed weights or equal weights)\n",
    "class_weights = torch.tensor(class_weights_array, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Loss function: Focal Loss with class weights\n",
    "\n",
    "focal_config = CONFIG['focal_loss']\n",
    "\n",
    "criterion = FocalLoss(\n",
    "\n",
    "    alpha=focal_config['alpha'], \n",
    "\n",
    "    gamma=focal_config['gamma'], \n",
    "\n",
    "    weight=class_weights, \n",
    "\n",
    "    reduction='mean'\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "train_config = CONFIG['training']\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "\n",
    "    model.parameters(), \n",
    "\n",
    "    lr=train_config['initial_lr'], \n",
    "\n",
    "    weight_decay=train_config['weight_decay']\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Learning rate scheduler with warmup and cosine annealing\n",
    "\n",
    "scheduler = WarmupCosineScheduler(\n",
    "\n",
    "    optimizer, \n",
    "\n",
    "    warmup_epochs=train_config['warmup_epochs'], \n",
    "\n",
    "    total_epochs=train_config['num_epochs'], \n",
    "\n",
    "    min_lr=train_config['min_lr']\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Output directory\n",
    "\n",
    "OUTPUT_DIR = DATA_DIR / 'improved_models'\n",
    "\n",
    "save_dir = OUTPUT_DIR / 'hybrid_cnn_mlp_v4_3_enhanced'\n",
    "\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"\\nTraining configuration:\")\n",
    "\n",
    "logger.info(f\"- Epochs: {train_config['num_epochs']}\")\n",
    "\n",
    "logger.info(f\"- Warmup epochs: {train_config['warmup_epochs']}\")\n",
    "\n",
    "logger.info(f\"- Initial LR: {train_config['initial_lr']}\")\n",
    "\n",
    "logger.info(f\"- Loss function: Focal Loss (alpha={focal_config['alpha']}, gamma={focal_config['gamma']})\")\n",
    "\n",
    "logger.info(f\"- Gradient clipping: {train_config['max_grad_norm']}\")\n",
    "\n",
    "logger.info(f\"- Early stopping patience: {train_config['early_stopping_patience']}\")\n",
    "\n",
    "logger.info(f\"- Dropout: {train_config['dropout']}\")\n",
    "\n",
    "logger.info(f\"- SpecAugment: Enabled for training\")\n",
    "\n",
    "logger.info(f\"- Context windows: ±100ms (V2 with VOT and burst features)\")\n",
    "\n",
    "logger.info(f\"- Save directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 23:06:32,843 - INFO - \n",
      "Epoch 1/200\n",
      "2026-01-06 23:06:32,844 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:07:17,520 - INFO - Train Loss: 0.0340, Train Acc: 0.7511\n",
      "2026-01-06 23:07:17,521 - INFO - Val Loss: 0.0243, Val Acc: 0.8199\n",
      "2026-01-06 23:07:17,521 - INFO - Val F1: 0.8234, Val ROC-AUC: 0.9199\n",
      "2026-01-06 23:07:17,521 - INFO - Learning Rate: 0.000100\n",
      "2026-01-06 23:07:17,733 - INFO - ✓ New best model saved! (F1: 0.8234)\n",
      "2026-01-06 23:07:17,734 - INFO - \n",
      "Epoch 2/200\n",
      "2026-01-06 23:07:17,734 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:07:58,112 - INFO - Train Loss: 0.0270, Train Acc: 0.8105\n",
      "2026-01-06 23:07:58,112 - INFO - Val Loss: 0.0229, Val Acc: 0.8423\n",
      "2026-01-06 23:07:58,113 - INFO - Val F1: 0.8449, Val ROC-AUC: 0.9278\n",
      "2026-01-06 23:07:58,113 - INFO - Learning Rate: 0.000200\n",
      "2026-01-06 23:07:58,272 - INFO - ✓ New best model saved! (F1: 0.8449)\n",
      "2026-01-06 23:07:58,273 - INFO - \n",
      "Epoch 3/200\n",
      "2026-01-06 23:07:58,273 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:08:39,196 - INFO - Train Loss: 0.0259, Train Acc: 0.8191\n",
      "2026-01-06 23:08:39,196 - INFO - Val Loss: 0.0237, Val Acc: 0.8178\n",
      "2026-01-06 23:08:39,196 - INFO - Val F1: 0.8215, Val ROC-AUC: 0.9323\n",
      "2026-01-06 23:08:39,197 - INFO - Learning Rate: 0.000300\n",
      "2026-01-06 23:08:39,197 - INFO - \n",
      "Epoch 4/200\n",
      "2026-01-06 23:08:39,197 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:09:34,477 - INFO - Train Loss: 0.0247, Train Acc: 0.8322\n",
      "2026-01-06 23:09:34,477 - INFO - Val Loss: 0.0218, Val Acc: 0.8484\n",
      "2026-01-06 23:09:34,477 - INFO - Val F1: 0.8509, Val ROC-AUC: 0.9343\n",
      "2026-01-06 23:09:34,478 - INFO - Learning Rate: 0.000400\n",
      "2026-01-06 23:09:34,701 - INFO - ✓ New best model saved! (F1: 0.8509)\n",
      "2026-01-06 23:09:34,702 - INFO - \n",
      "Epoch 5/200\n",
      "2026-01-06 23:09:34,702 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:10:26,054 - INFO - Train Loss: 0.0239, Train Acc: 0.8359\n",
      "2026-01-06 23:10:26,054 - INFO - Val Loss: 0.0215, Val Acc: 0.8575\n",
      "2026-01-06 23:10:26,054 - INFO - Val F1: 0.8599, Val ROC-AUC: 0.9404\n",
      "2026-01-06 23:10:26,055 - INFO - Learning Rate: 0.000500\n",
      "2026-01-06 23:10:26,227 - INFO - ✓ New best model saved! (F1: 0.8599)\n",
      "2026-01-06 23:10:26,227 - INFO - \n",
      "Epoch 6/200\n",
      "2026-01-06 23:10:26,228 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:11:17,800 - INFO - Train Loss: 0.0227, Train Acc: 0.8507\n",
      "2026-01-06 23:11:17,800 - INFO - Val Loss: 0.0210, Val Acc: 0.8566\n",
      "2026-01-06 23:11:17,801 - INFO - Val F1: 0.8590, Val ROC-AUC: 0.9404\n",
      "2026-01-06 23:11:17,801 - INFO - Learning Rate: 0.000500\n",
      "2026-01-06 23:11:17,801 - INFO - \n",
      "Epoch 7/200\n",
      "2026-01-06 23:11:17,802 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:12:09,368 - INFO - Train Loss: 0.0219, Train Acc: 0.8577\n",
      "2026-01-06 23:12:09,369 - INFO - Val Loss: 0.0211, Val Acc: 0.8457\n",
      "2026-01-06 23:12:09,369 - INFO - Val F1: 0.8487, Val ROC-AUC: 0.9436\n",
      "2026-01-06 23:12:09,369 - INFO - Learning Rate: 0.000500\n",
      "2026-01-06 23:12:09,369 - INFO - \n",
      "Epoch 8/200\n",
      "2026-01-06 23:12:09,370 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:13:02,750 - INFO - Train Loss: 0.0216, Train Acc: 0.8582\n",
      "2026-01-06 23:13:02,751 - INFO - Val Loss: 0.0200, Val Acc: 0.8573\n",
      "2026-01-06 23:13:02,751 - INFO - Val F1: 0.8598, Val ROC-AUC: 0.9454\n",
      "2026-01-06 23:13:02,751 - INFO - Learning Rate: 0.000500\n",
      "2026-01-06 23:13:02,752 - INFO - \n",
      "Epoch 9/200\n",
      "2026-01-06 23:13:02,752 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:13:56,829 - INFO - Train Loss: 0.0211, Train Acc: 0.8616\n",
      "2026-01-06 23:13:56,829 - INFO - Val Loss: 0.0202, Val Acc: 0.8622\n",
      "2026-01-06 23:13:56,830 - INFO - Val F1: 0.8645, Val ROC-AUC: 0.9460\n",
      "2026-01-06 23:13:56,830 - INFO - Learning Rate: 0.000499\n",
      "2026-01-06 23:13:57,004 - INFO - ✓ New best model saved! (F1: 0.8645)\n",
      "2026-01-06 23:13:57,007 - INFO - \n",
      "Epoch 10/200\n",
      "2026-01-06 23:13:57,007 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:14:49,049 - INFO - Train Loss: 0.0204, Train Acc: 0.8678\n",
      "2026-01-06 23:14:49,050 - INFO - Val Loss: 0.0206, Val Acc: 0.8541\n",
      "2026-01-06 23:14:49,050 - INFO - Val F1: 0.8568, Val ROC-AUC: 0.9440\n",
      "2026-01-06 23:14:49,050 - INFO - Learning Rate: 0.000499\n",
      "2026-01-06 23:14:49,050 - INFO - \n",
      "Epoch 11/200\n",
      "2026-01-06 23:14:49,051 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:15:51,519 - INFO - Train Loss: 0.0204, Train Acc: 0.8660\n",
      "2026-01-06 23:15:51,520 - INFO - Val Loss: 0.0218, Val Acc: 0.8404\n",
      "2026-01-06 23:15:51,520 - INFO - Val F1: 0.8437, Val ROC-AUC: 0.9471\n",
      "2026-01-06 23:15:51,520 - INFO - Learning Rate: 0.000499\n",
      "2026-01-06 23:15:51,520 - INFO - \n",
      "Epoch 12/200\n",
      "2026-01-06 23:15:51,521 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:16:55,961 - INFO - Train Loss: 0.0197, Train Acc: 0.8718\n",
      "2026-01-06 23:16:55,961 - INFO - Val Loss: 0.0197, Val Acc: 0.8684\n",
      "2026-01-06 23:16:55,961 - INFO - Val F1: 0.8705, Val ROC-AUC: 0.9470\n",
      "2026-01-06 23:16:55,962 - INFO - Learning Rate: 0.000498\n",
      "2026-01-06 23:16:56,151 - INFO - ✓ New best model saved! (F1: 0.8705)\n",
      "2026-01-06 23:16:56,151 - INFO - \n",
      "Epoch 13/200\n",
      "2026-01-06 23:16:56,152 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:17:51,973 - INFO - Train Loss: 0.0197, Train Acc: 0.8675\n",
      "2026-01-06 23:17:51,973 - INFO - Val Loss: 0.0216, Val Acc: 0.8390\n",
      "2026-01-06 23:17:51,973 - INFO - Val F1: 0.8423, Val ROC-AUC: 0.9484\n",
      "2026-01-06 23:17:51,974 - INFO - Learning Rate: 0.000498\n",
      "2026-01-06 23:17:51,974 - INFO - \n",
      "Epoch 14/200\n",
      "2026-01-06 23:17:51,974 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:18:46,997 - INFO - Train Loss: 0.0192, Train Acc: 0.8765\n",
      "2026-01-06 23:18:46,998 - INFO - Val Loss: 0.0198, Val Acc: 0.8684\n",
      "2026-01-06 23:18:46,998 - INFO - Val F1: 0.8704, Val ROC-AUC: 0.9464\n",
      "2026-01-06 23:18:46,998 - INFO - Learning Rate: 0.000497\n",
      "2026-01-06 23:18:46,998 - INFO - \n",
      "Epoch 15/200\n",
      "2026-01-06 23:18:46,999 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:19:44,453 - INFO - Train Loss: 0.0185, Train Acc: 0.8798\n",
      "2026-01-06 23:19:44,454 - INFO - Val Loss: 0.0212, Val Acc: 0.8421\n",
      "2026-01-06 23:19:44,454 - INFO - Val F1: 0.8453, Val ROC-AUC: 0.9488\n",
      "2026-01-06 23:19:44,454 - INFO - Learning Rate: 0.000497\n",
      "2026-01-06 23:19:44,454 - INFO - \n",
      "Epoch 16/200\n",
      "2026-01-06 23:19:44,455 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:20:45,522 - INFO - Train Loss: 0.0181, Train Acc: 0.8822\n",
      "2026-01-06 23:20:45,564 - INFO - Val Loss: 0.0204, Val Acc: 0.8669\n",
      "2026-01-06 23:20:45,565 - INFO - Val F1: 0.8691, Val ROC-AUC: 0.9474\n",
      "2026-01-06 23:20:45,573 - INFO - Learning Rate: 0.000496\n",
      "2026-01-06 23:20:45,576 - INFO - \n",
      "Epoch 17/200\n",
      "2026-01-06 23:20:45,581 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:21:42,028 - INFO - Train Loss: 0.0183, Train Acc: 0.8802\n",
      "2026-01-06 23:21:42,029 - INFO - Val Loss: 0.0197, Val Acc: 0.8668\n",
      "2026-01-06 23:21:42,029 - INFO - Val F1: 0.8689, Val ROC-AUC: 0.9495\n",
      "2026-01-06 23:21:42,029 - INFO - Learning Rate: 0.000495\n",
      "2026-01-06 23:21:42,029 - INFO - \n",
      "Epoch 18/200\n",
      "2026-01-06 23:21:42,030 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:22:34,423 - INFO - Train Loss: 0.0183, Train Acc: 0.8825\n",
      "2026-01-06 23:22:34,423 - INFO - Val Loss: 0.0188, Val Acc: 0.8713\n",
      "2026-01-06 23:22:34,423 - INFO - Val F1: 0.8732, Val ROC-AUC: 0.9513\n",
      "2026-01-06 23:22:34,424 - INFO - Learning Rate: 0.000495\n",
      "2026-01-06 23:22:34,597 - INFO - ✓ New best model saved! (F1: 0.8732)\n",
      "2026-01-06 23:22:34,598 - INFO - \n",
      "Epoch 19/200\n",
      "2026-01-06 23:22:34,598 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:23:26,655 - INFO - Train Loss: 0.0172, Train Acc: 0.8891\n",
      "2026-01-06 23:23:26,655 - INFO - Val Loss: 0.0193, Val Acc: 0.8751\n",
      "2026-01-06 23:23:26,656 - INFO - Val F1: 0.8769, Val ROC-AUC: 0.9500\n",
      "2026-01-06 23:23:26,656 - INFO - Learning Rate: 0.000494\n",
      "2026-01-06 23:23:26,842 - INFO - ✓ New best model saved! (F1: 0.8769)\n",
      "2026-01-06 23:23:26,842 - INFO - \n",
      "Epoch 20/200\n",
      "2026-01-06 23:23:26,843 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:24:19,417 - INFO - Train Loss: 0.0175, Train Acc: 0.8862\n",
      "2026-01-06 23:24:19,418 - INFO - Val Loss: 0.0201, Val Acc: 0.8762\n",
      "2026-01-06 23:24:19,418 - INFO - Val F1: 0.8779, Val ROC-AUC: 0.9502\n",
      "2026-01-06 23:24:19,418 - INFO - Learning Rate: 0.000493\n",
      "2026-01-06 23:24:19,588 - INFO - ✓ New best model saved! (F1: 0.8779)\n",
      "2026-01-06 23:24:19,588 - INFO - \n",
      "Epoch 21/200\n",
      "2026-01-06 23:24:19,589 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:25:11,623 - INFO - Train Loss: 0.0170, Train Acc: 0.8920\n",
      "2026-01-06 23:25:11,624 - INFO - Val Loss: 0.0204, Val Acc: 0.8622\n",
      "2026-01-06 23:25:11,624 - INFO - Val F1: 0.8648, Val ROC-AUC: 0.9519\n",
      "2026-01-06 23:25:11,624 - INFO - Learning Rate: 0.000492\n",
      "2026-01-06 23:25:11,624 - INFO - \n",
      "Epoch 22/200\n",
      "2026-01-06 23:25:11,624 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:26:03,654 - INFO - Train Loss: 0.0167, Train Acc: 0.8931\n",
      "2026-01-06 23:26:03,654 - INFO - Val Loss: 0.0196, Val Acc: 0.8748\n",
      "2026-01-06 23:26:03,655 - INFO - Val F1: 0.8767, Val ROC-AUC: 0.9504\n",
      "2026-01-06 23:26:03,655 - INFO - Learning Rate: 0.000491\n",
      "2026-01-06 23:26:03,655 - INFO - \n",
      "Epoch 23/200\n",
      "2026-01-06 23:26:03,656 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:26:55,650 - INFO - Train Loss: 0.0162, Train Acc: 0.8954\n",
      "2026-01-06 23:26:55,650 - INFO - Val Loss: 0.0198, Val Acc: 0.8733\n",
      "2026-01-06 23:26:55,650 - INFO - Val F1: 0.8752, Val ROC-AUC: 0.9505\n",
      "2026-01-06 23:26:55,651 - INFO - Learning Rate: 0.000490\n",
      "2026-01-06 23:26:55,651 - INFO - \n",
      "Epoch 24/200\n",
      "2026-01-06 23:26:55,651 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:27:47,888 - INFO - Train Loss: 0.0172, Train Acc: 0.8892\n",
      "2026-01-06 23:27:47,888 - INFO - Val Loss: 0.0190, Val Acc: 0.8767\n",
      "2026-01-06 23:27:47,888 - INFO - Val F1: 0.8785, Val ROC-AUC: 0.9514\n",
      "2026-01-06 23:27:47,889 - INFO - Learning Rate: 0.000488\n",
      "2026-01-06 23:27:48,056 - INFO - ✓ New best model saved! (F1: 0.8785)\n",
      "2026-01-06 23:27:48,056 - INFO - \n",
      "Epoch 25/200\n",
      "2026-01-06 23:27:48,057 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:28:41,467 - INFO - Train Loss: 0.0162, Train Acc: 0.8951\n",
      "2026-01-06 23:28:41,468 - INFO - Val Loss: 0.0192, Val Acc: 0.8760\n",
      "2026-01-06 23:28:41,468 - INFO - Val F1: 0.8779, Val ROC-AUC: 0.9520\n",
      "2026-01-06 23:28:41,468 - INFO - Learning Rate: 0.000487\n",
      "2026-01-06 23:28:41,469 - INFO - \n",
      "Epoch 26/200\n",
      "2026-01-06 23:28:41,470 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:29:37,805 - INFO - Train Loss: 0.0159, Train Acc: 0.9009\n",
      "2026-01-06 23:29:37,805 - INFO - Val Loss: 0.0199, Val Acc: 0.8749\n",
      "2026-01-06 23:29:37,805 - INFO - Val F1: 0.8768, Val ROC-AUC: 0.9515\n",
      "2026-01-06 23:29:37,806 - INFO - Learning Rate: 0.000486\n",
      "2026-01-06 23:29:37,806 - INFO - \n",
      "Epoch 27/200\n",
      "2026-01-06 23:29:37,807 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:30:33,980 - INFO - Train Loss: 0.0159, Train Acc: 0.8988\n",
      "2026-01-06 23:30:33,981 - INFO - Val Loss: 0.0194, Val Acc: 0.8793\n",
      "2026-01-06 23:30:33,981 - INFO - Val F1: 0.8808, Val ROC-AUC: 0.9523\n",
      "2026-01-06 23:30:33,981 - INFO - Learning Rate: 0.000484\n",
      "2026-01-06 23:30:34,183 - INFO - ✓ New best model saved! (F1: 0.8808)\n",
      "2026-01-06 23:30:34,184 - INFO - \n",
      "Epoch 28/200\n",
      "2026-01-06 23:30:34,184 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:31:29,885 - INFO - Train Loss: 0.0157, Train Acc: 0.9021\n",
      "2026-01-06 23:31:29,886 - INFO - Val Loss: 0.0200, Val Acc: 0.8684\n",
      "2026-01-06 23:31:29,886 - INFO - Val F1: 0.8705, Val ROC-AUC: 0.9502\n",
      "2026-01-06 23:31:29,886 - INFO - Learning Rate: 0.000483\n",
      "2026-01-06 23:31:29,887 - INFO - \n",
      "Epoch 29/200\n",
      "2026-01-06 23:31:29,887 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:32:25,521 - INFO - Train Loss: 0.0156, Train Acc: 0.8994\n",
      "2026-01-06 23:32:25,521 - INFO - Val Loss: 0.0195, Val Acc: 0.8713\n",
      "2026-01-06 23:32:25,522 - INFO - Val F1: 0.8732, Val ROC-AUC: 0.9528\n",
      "2026-01-06 23:32:25,522 - INFO - Learning Rate: 0.000482\n",
      "2026-01-06 23:32:25,523 - INFO - \n",
      "Epoch 30/200\n",
      "2026-01-06 23:32:25,523 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:33:22,510 - INFO - Train Loss: 0.0152, Train Acc: 0.9036\n",
      "2026-01-06 23:33:22,510 - INFO - Val Loss: 0.0195, Val Acc: 0.8702\n",
      "2026-01-06 23:33:22,511 - INFO - Val F1: 0.8723, Val ROC-AUC: 0.9529\n",
      "2026-01-06 23:33:22,511 - INFO - Learning Rate: 0.000480\n",
      "2026-01-06 23:33:22,512 - INFO - \n",
      "Epoch 31/200\n",
      "2026-01-06 23:33:22,512 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:34:19,180 - INFO - Train Loss: 0.0152, Train Acc: 0.9062\n",
      "2026-01-06 23:34:19,180 - INFO - Val Loss: 0.0198, Val Acc: 0.8728\n",
      "2026-01-06 23:34:19,181 - INFO - Val F1: 0.8748, Val ROC-AUC: 0.9524\n",
      "2026-01-06 23:34:19,181 - INFO - Learning Rate: 0.000478\n",
      "2026-01-06 23:34:19,182 - INFO - \n",
      "Epoch 32/200\n",
      "2026-01-06 23:34:19,182 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:35:15,587 - INFO - Train Loss: 0.0154, Train Acc: 0.9008\n",
      "2026-01-06 23:35:15,588 - INFO - Val Loss: 0.0198, Val Acc: 0.8767\n",
      "2026-01-06 23:35:15,588 - INFO - Val F1: 0.8782, Val ROC-AUC: 0.9500\n",
      "2026-01-06 23:35:15,588 - INFO - Learning Rate: 0.000477\n",
      "2026-01-06 23:35:15,589 - INFO - \n",
      "Epoch 33/200\n",
      "2026-01-06 23:35:15,589 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:36:12,414 - INFO - Train Loss: 0.0152, Train Acc: 0.9031\n",
      "2026-01-06 23:36:12,415 - INFO - Val Loss: 0.0194, Val Acc: 0.8673\n",
      "2026-01-06 23:36:12,415 - INFO - Val F1: 0.8697, Val ROC-AUC: 0.9522\n",
      "2026-01-06 23:36:12,415 - INFO - Learning Rate: 0.000475\n",
      "2026-01-06 23:36:12,416 - INFO - \n",
      "Epoch 34/200\n",
      "2026-01-06 23:36:12,417 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:37:08,959 - INFO - Train Loss: 0.0144, Train Acc: 0.9110\n",
      "2026-01-06 23:37:08,960 - INFO - Val Loss: 0.0203, Val Acc: 0.8800\n",
      "2026-01-06 23:37:08,960 - INFO - Val F1: 0.8814, Val ROC-AUC: 0.9515\n",
      "2026-01-06 23:37:08,961 - INFO - Learning Rate: 0.000473\n",
      "2026-01-06 23:37:09,182 - INFO - ✓ New best model saved! (F1: 0.8814)\n",
      "2026-01-06 23:37:09,183 - INFO - \n",
      "Epoch 35/200\n",
      "2026-01-06 23:37:09,183 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:38:03,890 - INFO - Train Loss: 0.0142, Train Acc: 0.9135\n",
      "2026-01-06 23:38:03,890 - INFO - Val Loss: 0.0203, Val Acc: 0.8777\n",
      "2026-01-06 23:38:03,891 - INFO - Val F1: 0.8793, Val ROC-AUC: 0.9514\n",
      "2026-01-06 23:38:03,891 - INFO - Learning Rate: 0.000471\n",
      "2026-01-06 23:38:03,891 - INFO - \n",
      "Epoch 36/200\n",
      "2026-01-06 23:38:03,892 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:38:59,418 - INFO - Train Loss: 0.0143, Train Acc: 0.9100\n",
      "2026-01-06 23:38:59,418 - INFO - Val Loss: 0.0204, Val Acc: 0.8664\n",
      "2026-01-06 23:38:59,419 - INFO - Val F1: 0.8685, Val ROC-AUC: 0.9504\n",
      "2026-01-06 23:38:59,419 - INFO - Learning Rate: 0.000470\n",
      "2026-01-06 23:38:59,419 - INFO - \n",
      "Epoch 37/200\n",
      "2026-01-06 23:38:59,420 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:39:54,965 - INFO - Train Loss: 0.0141, Train Acc: 0.9119\n",
      "2026-01-06 23:39:54,966 - INFO - Val Loss: 0.0199, Val Acc: 0.8806\n",
      "2026-01-06 23:39:54,966 - INFO - Val F1: 0.8823, Val ROC-AUC: 0.9531\n",
      "2026-01-06 23:39:54,967 - INFO - Learning Rate: 0.000468\n",
      "2026-01-06 23:39:55,156 - INFO - ✓ New best model saved! (F1: 0.8823)\n",
      "2026-01-06 23:39:55,157 - INFO - \n",
      "Epoch 38/200\n",
      "2026-01-06 23:39:55,157 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:40:48,371 - INFO - Train Loss: 0.0140, Train Acc: 0.9126\n",
      "2026-01-06 23:40:48,371 - INFO - Val Loss: 0.0198, Val Acc: 0.8733\n",
      "2026-01-06 23:40:48,371 - INFO - Val F1: 0.8752, Val ROC-AUC: 0.9520\n",
      "2026-01-06 23:40:48,372 - INFO - Learning Rate: 0.000466\n",
      "2026-01-06 23:40:48,372 - INFO - \n",
      "Epoch 39/200\n",
      "2026-01-06 23:40:48,372 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:41:46,643 - INFO - Train Loss: 0.0139, Train Acc: 0.9145\n",
      "2026-01-06 23:41:46,644 - INFO - Val Loss: 0.0195, Val Acc: 0.8831\n",
      "2026-01-06 23:41:46,644 - INFO - Val F1: 0.8845, Val ROC-AUC: 0.9536\n",
      "2026-01-06 23:41:46,644 - INFO - Learning Rate: 0.000463\n",
      "2026-01-06 23:41:46,870 - INFO - ✓ New best model saved! (F1: 0.8845)\n",
      "2026-01-06 23:41:46,871 - INFO - \n",
      "Epoch 40/200\n",
      "2026-01-06 23:41:46,871 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:42:45,135 - INFO - Train Loss: 0.0136, Train Acc: 0.9153\n",
      "2026-01-06 23:42:45,135 - INFO - Val Loss: 0.0199, Val Acc: 0.8818\n",
      "2026-01-06 23:42:45,136 - INFO - Val F1: 0.8832, Val ROC-AUC: 0.9529\n",
      "2026-01-06 23:42:45,136 - INFO - Learning Rate: 0.000461\n",
      "2026-01-06 23:42:45,137 - INFO - \n",
      "Epoch 41/200\n",
      "2026-01-06 23:42:45,137 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:43:44,404 - INFO - Train Loss: 0.0139, Train Acc: 0.9156\n",
      "2026-01-06 23:43:44,405 - INFO - Val Loss: 0.0197, Val Acc: 0.8744\n",
      "2026-01-06 23:43:44,405 - INFO - Val F1: 0.8764, Val ROC-AUC: 0.9541\n",
      "2026-01-06 23:43:44,405 - INFO - Learning Rate: 0.000459\n",
      "2026-01-06 23:43:44,406 - INFO - \n",
      "Epoch 42/200\n",
      "2026-01-06 23:43:44,406 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:44:44,548 - INFO - Train Loss: 0.0134, Train Acc: 0.9167\n",
      "2026-01-06 23:44:44,549 - INFO - Val Loss: 0.0216, Val Acc: 0.8773\n",
      "2026-01-06 23:44:44,550 - INFO - Val F1: 0.8789, Val ROC-AUC: 0.9513\n",
      "2026-01-06 23:44:44,550 - INFO - Learning Rate: 0.000457\n",
      "2026-01-06 23:44:44,550 - INFO - \n",
      "Epoch 43/200\n",
      "2026-01-06 23:44:44,551 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:45:44,412 - INFO - Train Loss: 0.0135, Train Acc: 0.9166\n",
      "2026-01-06 23:45:44,413 - INFO - Val Loss: 0.0203, Val Acc: 0.8769\n",
      "2026-01-06 23:45:44,415 - INFO - Val F1: 0.8787, Val ROC-AUC: 0.9511\n",
      "2026-01-06 23:45:44,417 - INFO - Learning Rate: 0.000455\n",
      "2026-01-06 23:45:44,420 - INFO - \n",
      "Epoch 44/200\n",
      "2026-01-06 23:45:44,423 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:46:43,826 - INFO - Train Loss: 0.0133, Train Acc: 0.9189\n",
      "2026-01-06 23:46:43,827 - INFO - Val Loss: 0.0208, Val Acc: 0.8838\n",
      "2026-01-06 23:46:43,827 - INFO - Val F1: 0.8852, Val ROC-AUC: 0.9520\n",
      "2026-01-06 23:46:43,827 - INFO - Learning Rate: 0.000452\n",
      "2026-01-06 23:46:44,024 - INFO - ✓ New best model saved! (F1: 0.8852)\n",
      "2026-01-06 23:46:44,025 - INFO - \n",
      "Epoch 45/200\n",
      "2026-01-06 23:46:44,025 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:47:49,735 - INFO - Train Loss: 0.0130, Train Acc: 0.9217\n",
      "2026-01-06 23:47:49,736 - INFO - Val Loss: 0.0211, Val Acc: 0.8728\n",
      "2026-01-06 23:47:49,736 - INFO - Val F1: 0.8748, Val ROC-AUC: 0.9513\n",
      "2026-01-06 23:47:49,737 - INFO - Learning Rate: 0.000450\n",
      "2026-01-06 23:47:49,738 - INFO - \n",
      "Epoch 46/200\n",
      "2026-01-06 23:47:49,739 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:48:50,174 - INFO - Train Loss: 0.0130, Train Acc: 0.9207\n",
      "2026-01-06 23:48:50,175 - INFO - Val Loss: 0.0210, Val Acc: 0.8895\n",
      "2026-01-06 23:48:50,176 - INFO - Val F1: 0.8902, Val ROC-AUC: 0.9521\n",
      "2026-01-06 23:48:50,176 - INFO - Learning Rate: 0.000448\n",
      "2026-01-06 23:48:50,406 - INFO - ✓ New best model saved! (F1: 0.8902)\n",
      "2026-01-06 23:48:50,406 - INFO - \n",
      "Epoch 47/200\n",
      "2026-01-06 23:48:50,406 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:49:43,978 - INFO - Train Loss: 0.0130, Train Acc: 0.9192\n",
      "2026-01-06 23:49:43,979 - INFO - Val Loss: 0.0210, Val Acc: 0.8836\n",
      "2026-01-06 23:49:43,979 - INFO - Val F1: 0.8849, Val ROC-AUC: 0.9520\n",
      "2026-01-06 23:49:43,979 - INFO - Learning Rate: 0.000445\n",
      "2026-01-06 23:49:43,979 - INFO - \n",
      "Epoch 48/200\n",
      "2026-01-06 23:49:43,980 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:50:38,524 - INFO - Train Loss: 0.0131, Train Acc: 0.9199\n",
      "2026-01-06 23:50:38,525 - INFO - Val Loss: 0.0198, Val Acc: 0.8813\n",
      "2026-01-06 23:50:38,525 - INFO - Val F1: 0.8826, Val ROC-AUC: 0.9521\n",
      "2026-01-06 23:50:38,525 - INFO - Learning Rate: 0.000442\n",
      "2026-01-06 23:50:38,526 - INFO - \n",
      "Epoch 49/200\n",
      "2026-01-06 23:50:38,526 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:51:39,593 - INFO - Train Loss: 0.0127, Train Acc: 0.9234\n",
      "2026-01-06 23:51:39,595 - INFO - Val Loss: 0.0202, Val Acc: 0.8827\n",
      "2026-01-06 23:51:39,596 - INFO - Val F1: 0.8842, Val ROC-AUC: 0.9533\n",
      "2026-01-06 23:51:39,602 - INFO - Learning Rate: 0.000440\n",
      "2026-01-06 23:51:39,605 - INFO - \n",
      "Epoch 50/200\n",
      "2026-01-06 23:51:39,606 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:52:36,738 - INFO - Train Loss: 0.0125, Train Acc: 0.9243\n",
      "2026-01-06 23:52:36,741 - INFO - Val Loss: 0.0208, Val Acc: 0.8789\n",
      "2026-01-06 23:52:36,743 - INFO - Val F1: 0.8806, Val ROC-AUC: 0.9532\n",
      "2026-01-06 23:52:36,744 - INFO - Learning Rate: 0.000437\n",
      "2026-01-06 23:52:36,745 - INFO - \n",
      "Epoch 51/200\n",
      "2026-01-06 23:52:36,747 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:53:32,957 - INFO - Train Loss: 0.0126, Train Acc: 0.9229\n",
      "2026-01-06 23:53:32,957 - INFO - Val Loss: 0.0218, Val Acc: 0.8807\n",
      "2026-01-06 23:53:32,958 - INFO - Val F1: 0.8823, Val ROC-AUC: 0.9507\n",
      "2026-01-06 23:53:32,958 - INFO - Learning Rate: 0.000435\n",
      "2026-01-06 23:53:32,958 - INFO - \n",
      "Epoch 52/200\n",
      "2026-01-06 23:53:32,958 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:54:37,422 - INFO - Train Loss: 0.0126, Train Acc: 0.9233\n",
      "2026-01-06 23:54:37,423 - INFO - Val Loss: 0.0213, Val Acc: 0.8860\n",
      "2026-01-06 23:54:37,423 - INFO - Val F1: 0.8869, Val ROC-AUC: 0.9522\n",
      "2026-01-06 23:54:37,423 - INFO - Learning Rate: 0.000432\n",
      "2026-01-06 23:54:37,424 - INFO - \n",
      "Epoch 53/200\n",
      "2026-01-06 23:54:37,424 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:55:36,531 - INFO - Train Loss: 0.0123, Train Acc: 0.9258\n",
      "2026-01-06 23:55:36,532 - INFO - Val Loss: 0.0201, Val Acc: 0.8905\n",
      "2026-01-06 23:55:36,532 - INFO - Val F1: 0.8913, Val ROC-AUC: 0.9521\n",
      "2026-01-06 23:55:36,532 - INFO - Learning Rate: 0.000429\n",
      "2026-01-06 23:55:36,725 - INFO - ✓ New best model saved! (F1: 0.8913)\n",
      "2026-01-06 23:55:36,725 - INFO - \n",
      "Epoch 54/200\n",
      "2026-01-06 23:55:36,725 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:56:36,001 - INFO - Train Loss: 0.0120, Train Acc: 0.9292\n",
      "2026-01-06 23:56:36,002 - INFO - Val Loss: 0.0202, Val Acc: 0.8853\n",
      "2026-01-06 23:56:36,002 - INFO - Val F1: 0.8866, Val ROC-AUC: 0.9533\n",
      "2026-01-06 23:56:36,003 - INFO - Learning Rate: 0.000426\n",
      "2026-01-06 23:56:36,003 - INFO - \n",
      "Epoch 55/200\n",
      "2026-01-06 23:56:36,004 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:57:33,601 - INFO - Train Loss: 0.0121, Train Acc: 0.9261\n",
      "2026-01-06 23:57:33,602 - INFO - Val Loss: 0.0212, Val Acc: 0.8791\n",
      "2026-01-06 23:57:33,602 - INFO - Val F1: 0.8807, Val ROC-AUC: 0.9525\n",
      "2026-01-06 23:57:33,603 - INFO - Learning Rate: 0.000423\n",
      "2026-01-06 23:57:33,603 - INFO - \n",
      "Epoch 56/200\n",
      "2026-01-06 23:57:33,604 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:58:32,168 - INFO - Train Loss: 0.0121, Train Acc: 0.9286\n",
      "2026-01-06 23:58:32,169 - INFO - Val Loss: 0.0205, Val Acc: 0.8871\n",
      "2026-01-06 23:58:32,169 - INFO - Val F1: 0.8881, Val ROC-AUC: 0.9518\n",
      "2026-01-06 23:58:32,169 - INFO - Learning Rate: 0.000420\n",
      "2026-01-06 23:58:32,169 - INFO - \n",
      "Epoch 57/200\n",
      "2026-01-06 23:58:32,170 - INFO - --------------------------------------------------\n",
      "2026-01-06 23:59:22,068 - INFO - Train Loss: 0.0119, Train Acc: 0.9300\n",
      "2026-01-06 23:59:22,069 - INFO - Val Loss: 0.0216, Val Acc: 0.8873\n",
      "2026-01-06 23:59:22,070 - INFO - Val F1: 0.8884, Val ROC-AUC: 0.9535\n",
      "2026-01-06 23:59:22,070 - INFO - Learning Rate: 0.000417\n",
      "2026-01-06 23:59:22,070 - INFO - \n",
      "Epoch 58/200\n",
      "2026-01-06 23:59:22,071 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:00:10,281 - INFO - Train Loss: 0.0121, Train Acc: 0.9247\n",
      "2026-01-07 00:00:10,281 - INFO - Val Loss: 0.0206, Val Acc: 0.8873\n",
      "2026-01-07 00:00:10,282 - INFO - Val F1: 0.8883, Val ROC-AUC: 0.9523\n",
      "2026-01-07 00:00:10,282 - INFO - Learning Rate: 0.000414\n",
      "2026-01-07 00:00:10,283 - INFO - \n",
      "Epoch 59/200\n",
      "2026-01-07 00:00:10,283 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:01:00,244 - INFO - Train Loss: 0.0115, Train Acc: 0.9311\n",
      "2026-01-07 00:01:00,244 - INFO - Val Loss: 0.0209, Val Acc: 0.8876\n",
      "2026-01-07 00:01:00,244 - INFO - Val F1: 0.8887, Val ROC-AUC: 0.9524\n",
      "2026-01-07 00:01:00,245 - INFO - Learning Rate: 0.000411\n",
      "2026-01-07 00:01:00,245 - INFO - \n",
      "Epoch 60/200\n",
      "2026-01-07 00:01:00,245 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:01:51,638 - INFO - Train Loss: 0.0116, Train Acc: 0.9304\n",
      "2026-01-07 00:01:51,639 - INFO - Val Loss: 0.0206, Val Acc: 0.8911\n",
      "2026-01-07 00:01:51,639 - INFO - Val F1: 0.8918, Val ROC-AUC: 0.9533\n",
      "2026-01-07 00:01:51,639 - INFO - Learning Rate: 0.000408\n",
      "2026-01-07 00:01:51,850 - INFO - ✓ New best model saved! (F1: 0.8918)\n",
      "2026-01-07 00:01:51,850 - INFO - \n",
      "Epoch 61/200\n",
      "2026-01-07 00:01:51,851 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:02:42,989 - INFO - Train Loss: 0.0115, Train Acc: 0.9304\n",
      "2026-01-07 00:02:42,990 - INFO - Val Loss: 0.0211, Val Acc: 0.8804\n",
      "2026-01-07 00:02:42,990 - INFO - Val F1: 0.8820, Val ROC-AUC: 0.9516\n",
      "2026-01-07 00:02:42,990 - INFO - Learning Rate: 0.000405\n",
      "2026-01-07 00:02:42,991 - INFO - \n",
      "Epoch 62/200\n",
      "2026-01-07 00:02:42,991 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:03:31,048 - INFO - Train Loss: 0.0115, Train Acc: 0.9321\n",
      "2026-01-07 00:03:31,048 - INFO - Val Loss: 0.0221, Val Acc: 0.8806\n",
      "2026-01-07 00:03:31,049 - INFO - Val F1: 0.8821, Val ROC-AUC: 0.9529\n",
      "2026-01-07 00:03:31,049 - INFO - Learning Rate: 0.000402\n",
      "2026-01-07 00:03:31,049 - INFO - \n",
      "Epoch 63/200\n",
      "2026-01-07 00:03:31,049 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:04:18,758 - INFO - Train Loss: 0.0116, Train Acc: 0.9299\n",
      "2026-01-07 00:04:18,759 - INFO - Val Loss: 0.0225, Val Acc: 0.8876\n",
      "2026-01-07 00:04:18,759 - INFO - Val F1: 0.8884, Val ROC-AUC: 0.9525\n",
      "2026-01-07 00:04:18,759 - INFO - Learning Rate: 0.000399\n",
      "2026-01-07 00:04:18,759 - INFO - \n",
      "Epoch 64/200\n",
      "2026-01-07 00:04:18,759 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:05:08,858 - INFO - Train Loss: 0.0111, Train Acc: 0.9345\n",
      "2026-01-07 00:05:08,859 - INFO - Val Loss: 0.0230, Val Acc: 0.8865\n",
      "2026-01-07 00:05:08,859 - INFO - Val F1: 0.8874, Val ROC-AUC: 0.9520\n",
      "2026-01-07 00:05:08,859 - INFO - Learning Rate: 0.000396\n",
      "2026-01-07 00:05:08,860 - INFO - \n",
      "Epoch 65/200\n",
      "2026-01-07 00:05:08,860 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:05:59,787 - INFO - Train Loss: 0.0111, Train Acc: 0.9335\n",
      "2026-01-07 00:05:59,787 - INFO - Val Loss: 0.0217, Val Acc: 0.8907\n",
      "2026-01-07 00:05:59,787 - INFO - Val F1: 0.8912, Val ROC-AUC: 0.9511\n",
      "2026-01-07 00:05:59,787 - INFO - Learning Rate: 0.000392\n",
      "2026-01-07 00:05:59,792 - INFO - \n",
      "Epoch 66/200\n",
      "2026-01-07 00:05:59,796 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:06:49,205 - INFO - Train Loss: 0.0115, Train Acc: 0.9325\n",
      "2026-01-07 00:06:49,206 - INFO - Val Loss: 0.0234, Val Acc: 0.8816\n",
      "2026-01-07 00:06:49,206 - INFO - Val F1: 0.8829, Val ROC-AUC: 0.9507\n",
      "2026-01-07 00:06:49,206 - INFO - Learning Rate: 0.000389\n",
      "2026-01-07 00:06:49,207 - INFO - \n",
      "Epoch 67/200\n",
      "2026-01-07 00:06:49,207 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:07:42,516 - INFO - Train Loss: 0.0109, Train Acc: 0.9352\n",
      "2026-01-07 00:07:42,517 - INFO - Val Loss: 0.0222, Val Acc: 0.8871\n",
      "2026-01-07 00:07:42,518 - INFO - Val F1: 0.8881, Val ROC-AUC: 0.9526\n",
      "2026-01-07 00:07:42,518 - INFO - Learning Rate: 0.000386\n",
      "2026-01-07 00:07:42,519 - INFO - \n",
      "Epoch 68/200\n",
      "2026-01-07 00:07:42,520 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:08:35,391 - INFO - Train Loss: 0.0108, Train Acc: 0.9373\n",
      "2026-01-07 00:08:35,392 - INFO - Val Loss: 0.0217, Val Acc: 0.8815\n",
      "2026-01-07 00:08:35,392 - INFO - Val F1: 0.8831, Val ROC-AUC: 0.9528\n",
      "2026-01-07 00:08:35,393 - INFO - Learning Rate: 0.000382\n",
      "2026-01-07 00:08:35,394 - INFO - \n",
      "Epoch 69/200\n",
      "2026-01-07 00:08:35,394 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:09:27,722 - INFO - Train Loss: 0.0108, Train Acc: 0.9358\n",
      "2026-01-07 00:09:27,722 - INFO - Val Loss: 0.0215, Val Acc: 0.8865\n",
      "2026-01-07 00:09:27,723 - INFO - Val F1: 0.8877, Val ROC-AUC: 0.9537\n",
      "2026-01-07 00:09:27,723 - INFO - Learning Rate: 0.000379\n",
      "2026-01-07 00:09:27,724 - INFO - \n",
      "Epoch 70/200\n",
      "2026-01-07 00:09:27,724 - INFO - --------------------------------------------------\n",
      "2026-01-07 00:10:21,108 - INFO - Train Loss: 0.0108, Train Acc: 0.9356\n",
      "2026-01-07 00:10:21,111 - INFO - Val Loss: 0.0225, Val Acc: 0.8824\n",
      "2026-01-07 00:10:21,112 - INFO - Val F1: 0.8836, Val ROC-AUC: 0.9520\n",
      "2026-01-07 00:10:21,114 - INFO - Learning Rate: 0.000375\n",
      "2026-01-07 00:10:21,115 - INFO - \n",
      "Early stopping at epoch 70\n",
      "2026-01-07 00:10:21,117 - INFO - Best F1: 0.8918 at epoch 60\n",
      "2026-01-07 00:10:25,404 - INFO -                           \n",
      "============================================================\n",
      "2026-01-07 00:10:25,404 - INFO - Final Test Results:\n",
      "2026-01-07 00:10:25,404 - INFO - ============================================================\n",
      "2026-01-07 00:10:25,404 - INFO - Accuracy: 0.8953\n",
      "2026-01-07 00:10:25,405 - INFO - F1-score: 0.8959\n",
      "2026-01-07 00:10:25,405 - INFO - ROC-AUC: 0.9569\n",
      "2026-01-07 00:10:25,406 - INFO - Precision: 0.8974\n",
      "2026-01-07 00:10:25,406 - INFO - Recall: 0.8953\n",
      "2026-01-07 00:10:25,407 - INFO - Best epoch: 60\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_config = CONFIG['training']\n",
    "history, best_epoch = train_model(\n",
    "    model, train_hybrid_loader, val_hybrid_loader, criterion, optimizer, scheduler,\n",
    "    device, num_epochs=train_config['num_epochs'], save_dir=save_dir, \n",
    "    model_name='hybrid_cnn_mlp_v4_3_enhanced', \n",
    "    early_stopping_patience=train_config['early_stopping_patience'], \n",
    "    max_grad_norm=train_config['max_grad_norm']\n",
    ")\n",
    "\n",
    "# Load best model and evaluate on test set\n",
    "checkpoint = torch.load(save_dir / 'best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_metrics, test_preds, test_labels, test_probs = evaluate_model(\n",
    "    model, test_hybrid_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Save test metrics\n",
    "with open(save_dir / 'test_metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "logger.info(f\"\\n{'='*60}\")\n",
    "logger.info(f\"Final Test Results:\")\n",
    "logger.info(f\"{'='*60}\")\n",
    "logger.info(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "logger.info(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
    "logger.info(f\"ROC-AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "logger.info(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "logger.info(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "logger.info(f\"Best epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions with Probabilities (Optimized with Vectorized Operations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 00:10:25,514 - INFO - Saved predictions with probabilities to: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2/improved_models/hybrid_cnn_mlp_v4_3_enhanced/test_predictions_with_probs.csv\n",
      "2026-01-07 00:10:25,515 - INFO - Total predictions: 5523\n",
      "2026-01-07 00:10:25,516 - INFO - Correct predictions: 4945\n",
      "2026-01-07 00:10:25,517 - INFO - Incorrect predictions: 578\n",
      "2026-01-07 00:10:25,521 - INFO - \n",
      "Summary Statistics:\n",
      "2026-01-07 00:10:25,521 - INFO - - Average confidence (correct): 0.8230\n",
      "2026-01-07 00:10:25,522 - INFO - - Average confidence (incorrect): 0.6702\n",
      "2026-01-07 00:10:25,522 - INFO - - High confidence errors (>0.8): 80\n",
      "2026-01-07 00:10:25,522 - INFO - - Low confidence errors (<0.6): 187\n"
     ]
    }
   ],
   "source": [
    "# Get test dataset to extract phoneme metadata\n",
    "test_df = df[df['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "# Get class names from label encoder\n",
    "class_names = le.classes_\n",
    "\n",
    "# Use vectorized operations instead of iterrows for better performance\n",
    "# Ensure alignment between test_df and predictions\n",
    "assert len(test_df) == len(test_labels) == len(test_preds) == len(test_probs), \\\n",
    "    f\"Length mismatch: test_df={len(test_df)}, labels={len(test_labels)}, preds={len(test_preds)}, probs={len(test_probs)}\"\n",
    "\n",
    "# Convert to numpy arrays for vectorized comparison\n",
    "test_labels = np.array(test_labels)\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "# Create predictions dataframe using vectorized operations\n",
    "predictions_data = {\n",
    "    'phoneme_id': test_df['phoneme_id'].values,\n",
    "    'utterance_id': test_df.get('utterance_id', pd.Series([None] * len(test_df))).values,\n",
    "    'phoneme': test_df.get('phoneme', test_df.get('class', pd.Series([None] * len(test_df)))).values,\n",
    "    'true_class': test_df['class'].values,\n",
    "    'true_class_encoded': test_labels,\n",
    "    'predicted_class_encoded': test_preds,\n",
    "    'predicted_class': np.where(test_preds == 0, class_names[0], class_names[1]),  # oː=0, ɔ=1\n",
    "    'prob_class_0': [p[0] for p in test_probs],\n",
    "    'prob_class_1': [p[1] for p in test_probs],\n",
    "    'max_prob': [np.max(p) for p in test_probs],\n",
    "    'is_correct': (test_labels == test_preds).astype(int),\n",
    "    'duration_ms': test_df.get('duration_ms', pd.Series([None] * len(test_df))).values\n",
    "}\n",
    "\n",
    "# Calculate confidence (max prob for correct, predicted prob for incorrect)\n",
    "confidence = []\n",
    "for i, (label, pred, prob) in enumerate(zip(test_labels, test_preds, test_probs)):\n",
    "    if label == pred:\n",
    "        confidence.append(float(np.max(prob)))\n",
    "    else:\n",
    "        confidence.append(float(prob[pred]))\n",
    "\n",
    "predictions_data['confidence'] = confidence\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv(save_dir / 'test_predictions_with_probs.csv', index=False)\n",
    "logger.info(f\"Saved predictions with probabilities to: {save_dir / 'test_predictions_with_probs.csv'}\")\n",
    "logger.info(f\"Total predictions: {len(predictions_df)}\")\n",
    "logger.info(f\"Correct predictions: {predictions_df['is_correct'].sum()}\")\n",
    "logger.info(f\"Incorrect predictions: {(~predictions_df['is_correct'].astype(bool)).sum()}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'total_samples': len(predictions_df),\n",
    "    'correct_predictions': int(predictions_df['is_correct'].sum()),\n",
    "    'incorrect_predictions': int((~predictions_df['is_correct'].astype(bool)).sum()),\n",
    "    'accuracy': float(predictions_df['is_correct'].mean()),\n",
    "    'avg_confidence_correct': float(predictions_df[predictions_df['is_correct'] == 1]['confidence'].mean()),\n",
    "    'avg_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].mean()),\n",
    "    'min_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].min()),\n",
    "    'max_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].max()),\n",
    "    'high_confidence_errors': int(((predictions_df['is_correct'] == 0) & (predictions_df['confidence'] > 0.8)).sum()),\n",
    "    'low_confidence_errors': int(((predictions_df['is_correct'] == 0) & (predictions_df['confidence'] < 0.6)).sum()),\n",
    "}\n",
    "\n",
    "with open(save_dir / 'predictions_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "logger.info(f\"\\nSummary Statistics:\")\n",
    "logger.info(f\"- Average confidence (correct): {summary_stats['avg_confidence_correct']:.4f}\")\n",
    "logger.info(f\"- Average confidence (incorrect): {summary_stats['avg_confidence_incorrect']:.4f}\")\n",
    "logger.info(f\"- High confidence errors (>0.8): {summary_stats['high_confidence_errors']}\")\n",
    "logger.info(f\"- Low confidence errors (<0.6): {summary_stats['low_confidence_errors']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Validation Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 00:10:28,477 - INFO - Saved validation predictions to: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2/improved_models/hybrid_cnn_mlp_v4_3_enhanced/val_predictions_with_probs.csv\n"
     ]
    }
   ],
   "source": [
    "# Get validation predictions\n",
    "val_metrics, val_preds, val_labels, val_probs = evaluate_model(model, val_hybrid_loader, criterion, device)\n",
    "val_df = df[df['split'] == 'val'].reset_index(drop=True)\n",
    "\n",
    "# Ensure alignment\n",
    "assert len(val_df) == len(val_labels) == len(val_preds) == len(val_probs), \\\n",
    "    f\"Length mismatch: val_df={len(val_df)}, labels={len(val_labels)}, preds={len(val_preds)}, probs={len(val_probs)}\"\n",
    "\n",
    "# Convert to numpy arrays for vectorized comparison\n",
    "val_labels = np.array(val_labels)\n",
    "val_preds = np.array(val_preds)\n",
    "\n",
    "# Use vectorized operations\n",
    "val_predictions_data = {\n",
    "    'phoneme_id': val_df['phoneme_id'].values,\n",
    "    'utterance_id': val_df.get('utterance_id', pd.Series([None] * len(val_df))).values,\n",
    "    'phoneme': val_df.get('phoneme', val_df.get('class', pd.Series([None] * len(val_df)))).values,\n",
    "    'true_class': val_df['class'].values,\n",
    "    'true_class_encoded': val_labels,\n",
    "    'predicted_class_encoded': val_preds,\n",
    "    'predicted_class': np.where(val_preds == 0, class_names[0], class_names[1]),  # oː=0, ɔ=1\n",
    "    'prob_class_0': [p[0] for p in val_probs],\n",
    "    'prob_class_1': [p[1] for p in val_probs],\n",
    "    'max_prob': [np.max(p) for p in val_probs],\n",
    "    'is_correct': (val_labels == val_preds).astype(int),\n",
    "    'duration_ms': val_df.get('duration_ms', pd.Series([None] * len(val_df))).values\n",
    "}\n",
    "\n",
    "# Calculate confidence\n",
    "val_confidence = []\n",
    "for i, (label, pred, prob) in enumerate(zip(val_labels, val_preds, val_probs)):\n",
    "    if label == pred:\n",
    "        val_confidence.append(float(np.max(prob)))\n",
    "    else:\n",
    "        val_confidence.append(float(prob[pred]))\n",
    "\n",
    "val_predictions_data['confidence'] = val_confidence\n",
    "val_predictions_df = pd.DataFrame(val_predictions_data)\n",
    "val_predictions_df.to_csv(save_dir / 'val_predictions_with_probs.csv', index=False)\n",
    "logger.info(f\"Saved validation predictions to: {save_dir / 'val_predictions_with_probs.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis\n",
    "\n",
    "Visualize confusion matrix to understand model errors per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 00:10:29,492 - INFO - Confusion matrix saved to: /Volumes/SSanDisk/SpeechRec-German/artifacts/oː-ɔ_dl_models_with_context_v2/improved_models/hybrid_cnn_mlp_v4_3_enhanced/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 00:10:29,541 - INFO - \n",
      "============================================================\n",
      "2026-01-07 00:10:29,541 - INFO - Confusion Matrix Analysis:\n",
      "2026-01-07 00:10:29,541 - INFO - ============================================================\n",
      "2026-01-07 00:10:29,542 - INFO - \n",
      "True Class: oː\n",
      "2026-01-07 00:10:29,542 - INFO -   Total samples: 2009\n",
      "2026-01-07 00:10:29,542 - INFO -   Correctly predicted: 1779 (88.55%)\n",
      "2026-01-07 00:10:29,542 - INFO -   Incorrectly predicted: 230\n",
      "2026-01-07 00:10:29,542 - INFO -     → Misclassified as 'ɔ': 230 (11.45%)\n",
      "2026-01-07 00:10:29,543 - INFO - \n",
      "True Class: ɔ\n",
      "2026-01-07 00:10:29,543 - INFO -   Total samples: 3514\n",
      "2026-01-07 00:10:29,543 - INFO -   Correctly predicted: 3166 (90.10%)\n",
      "2026-01-07 00:10:29,543 - INFO -   Incorrectly predicted: 348\n",
      "2026-01-07 00:10:29,543 - INFO -     → Misclassified as 'oː': 348 (9.90%)\n",
      "2026-01-07 00:10:29,544 - INFO - \n",
      "============================================================\n",
      "2026-01-07 00:10:29,544 - INFO - Overall Statistics:\n",
      "2026-01-07 00:10:29,544 - INFO -   Total test samples: 5523\n",
      "2026-01-07 00:10:29,544 - INFO -   Correct predictions: 4945 (89.53%)\n",
      "2026-01-07 00:10:29,544 - INFO -   Total errors: 578 (10.47%)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create confusion matrix for test set\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Get class names from label encoder\n",
    "class_names = le.classes_\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Confusion matrix with counts\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_xlabel('Predicted Class', fontsize=12)\n",
    "axes[0].set_ylabel('True Class', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Confusion matrix with percentages\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "sns.heatmap(\n",
    "    cm_percent, \n",
    "    annot=True, \n",
    "    fmt='.1f', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_xlabel('Predicted Class', fontsize=12)\n",
    "axes[1].set_ylabel('True Class', fontsize=12)\n",
    "axes[1].set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "logger.info(f\"Confusion matrix saved to: {save_dir / 'confusion_matrix.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "logger.info(f\"\\n{'='*60}\")\n",
    "logger.info(f\"Confusion Matrix Analysis:\")\n",
    "logger.info(f\"{'='*60}\")\n",
    "for i, true_class in enumerate(class_names):\n",
    "    total_true = cm[i].sum()\n",
    "    correct = cm[i, i]\n",
    "    errors = total_true - correct\n",
    "    accuracy_per_class = (correct / total_true * 100) if total_true > 0 else 0\n",
    "    \n",
    "    logger.info(f\"\\nTrue Class: {true_class}\")\n",
    "    logger.info(f\"  Total samples: {total_true}\")\n",
    "    logger.info(f\"  Correctly predicted: {correct} ({accuracy_per_class:.2f}%)\")\n",
    "    logger.info(f\"  Incorrectly predicted: {errors}\")\n",
    "    \n",
    "    # Show error breakdown\n",
    "    for j, pred_class in enumerate(class_names):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            error_pct = (cm[i, j] / total_true * 100) if total_true > 0 else 0\n",
    "            logger.info(f\"    → Misclassified as '{pred_class}': {cm[i, j]} ({error_pct:.2f}%)\")\n",
    "\n",
    "# Calculate overall metrics\n",
    "total_samples = cm.sum()\n",
    "correct_predictions = cm.trace()\n",
    "total_errors = total_samples - correct_predictions\n",
    "\n",
    "logger.info(f\"\\n{'='*60}\")\n",
    "logger.info(f\"Overall Statistics:\")\n",
    "logger.info(f\"  Total test samples: {total_samples}\")\n",
    "logger.info(f\"  Correct predictions: {correct_predictions} ({correct_predictions/total_samples*100:.2f}%)\")\n",
    "logger.info(f\"  Total errors: {total_errors} ({total_errors/total_samples*100:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}