{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoneme dataset preparation\n",
    "\n",
    "Pipeline to build phoneme-level dataset from `data_wav` while excluding Hessisch accent. Code and comments are in English. Run cells step by step; heavy steps default to dry-run flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6ca829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Root paths\n",
    "# Determine project root (parent of notebooks directory)\nPROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "META_SRC = PROJECT_ROOT / 'data_wav' / 'metadata_wav.csv'\n",
    "META_NO_HESS = PROJECT_ROOT / 'data_wav' / 'metadata_wav_no_hessisch.csv'\n",
    "# Audio already normalized/resampled by `02.convert_parquet_to_wav.ipynb`\n",
    "# so we reuse `data_wav` directly as the normalized source.\n",
    "AUDIO_ROOT = PROJECT_ROOT / 'data_wav'\n",
    "AUDIO_OUT = AUDIO_ROOT\n",
    "ALIGN_INPUT = PROJECT_ROOT / 'artifacts' / 'align_input'\n",
    "ALIGN_OUTPUT = PROJECT_ROOT / 'artifacts' / 'align_output'\n",
    "PHONEME_TBL = PROJECT_ROOT / 'artifacts' / 'phoneme_intervals.csv'\n",
    "PHONEME_AUDIO = PROJECT_ROOT / 'artifacts' / 'phoneme_wav'\n",
    "LOG_PATH = PROJECT_ROOT / '.cursor' / 'debug.log'\n",
    "SESSION_ID = 'debug-session'\n",
    "RUN_ID = 'post-fix'\n",
    "\n",
    "ALIGN_INPUT.mkdir(parents=True, exist_ok=True)\n",
    "ALIGN_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "PHONEME_AUDIO.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def dbg_log(hypothesis_id: str, location: str, message: str, data: dict | None = None):\n",
    "    payload = {\n",
    "        \"sessionId\": SESSION_ID,\n",
    "        \"runId\": RUN_ID,\n",
    "        \"hypothesisId\": hypothesis_id,\n",
    "        \"location\": location,\n",
    "        \"message\": message,\n",
    "        \"data\": data or {},\n",
    "        \"timestamp\": int(time.time() * 1000),\n",
    "    }\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ccd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows original=39248, kept=37142, removed=2106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>subset</th>\n",
       "      <th>style</th>\n",
       "      <th>text</th>\n",
       "      <th>samplerate</th>\n",
       "      <th>durationSeconds</th>\n",
       "      <th>recording_year_month</th>\n",
       "      <th>microphone</th>\n",
       "      <th>language</th>\n",
       "      <th>comment</th>\n",
       "      <th>audio_wav_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...</td>\n",
       "      <td>TV-2021.02-Neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Man könnte sagen, ich sei für diese Aufgabe pr...</td>\n",
       "      <td>16000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>bad_usbHeadset</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/SSanDisk/SpeechRec-German/data_wav/TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...</td>\n",
       "      <td>TV-2021.02-Neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Das heutige vereinte System von Postleitzahlen...</td>\n",
       "      <td>16000</td>\n",
       "      <td>7.851562</td>\n",
       "      <td>2020-02</td>\n",
       "      <td>good_rodePodcaster</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/SSanDisk/SpeechRec-German/data_wav/TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...</td>\n",
       "      <td>TV-2021.02-Neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Eine komplizierte Story mit unzähligen Charakt...</td>\n",
       "      <td>16000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2020-02</td>\n",
       "      <td>good_rodePodcaster</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/SSanDisk/SpeechRec-German/data_wav/TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...</td>\n",
       "      <td>TV-2021.02-Neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Siehe weiter unten.</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.540039</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>bad_usbHeadset</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/SSanDisk/SpeechRec-German/data_wav/TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...</td>\n",
       "      <td>TV-2021.02-Neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Bei niedriger Last werden bis zu vier der acht...</td>\n",
       "      <td>16000</td>\n",
       "      <td>5.218750</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>bad_usbHeadset</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/SSanDisk/SpeechRec-German/data_wav/TV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                                 id              subset  \\\n",
       "0    0  4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...  TV-2021.02-Neutral   \n",
       "1    1  4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...  TV-2021.02-Neutral   \n",
       "2    2  4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...  TV-2021.02-Neutral   \n",
       "3    3  4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...  TV-2021.02-Neutral   \n",
       "4    4  4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...  TV-2021.02-Neutral   \n",
       "\n",
       "     style                                               text  samplerate  \\\n",
       "0  neutral  Man könnte sagen, ich sei für diese Aufgabe pr...       16000   \n",
       "1  neutral  Das heutige vereinte System von Postleitzahlen...       16000   \n",
       "2  neutral  Eine komplizierte Story mit unzähligen Charakt...       16000   \n",
       "3  neutral                                Siehe weiter unten.       16000   \n",
       "4  neutral  Bei niedriger Last werden bis zu vier der acht...       16000   \n",
       "\n",
       "   durationSeconds recording_year_month          microphone language comment  \\\n",
       "0         4.000000              2019-11      bad_usbHeadset   german     NaN   \n",
       "1         7.851562              2020-02  good_rodePodcaster   german     NaN   \n",
       "2         5.750000              2020-02  good_rodePodcaster   german     NaN   \n",
       "3         1.540039              2019-12      bad_usbHeadset   german     NaN   \n",
       "4         5.218750              2019-10      bad_usbHeadset   german     NaN   \n",
       "\n",
       "                                      audio_wav_path  \n",
       "0  /Volumes/SSanDisk/SpeechRec-German/data_wav/TV...  \n",
       "1  /Volumes/SSanDisk/SpeechRec-German/data_wav/TV...  \n",
       "2  /Volumes/SSanDisk/SpeechRec-German/data_wav/TV...  \n",
       "3  /Volumes/SSanDisk/SpeechRec-German/data_wav/TV...  \n",
       "4  /Volumes/SSanDisk/SpeechRec-German/data_wav/TV...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata, ensure Hessisch is excluded\n",
    "df = pd.read_csv(META_SRC)\n",
    "mask_no_hess = ~(df['subset'].str.contains('Hessisch', case=False, na=False) | df['style'].str.contains('Hessisch', case=False, na=False))\n",
    "df_no_hess = df[mask_no_hess].copy()\n",
    "print(f'Rows original={len(df)}, kept={len(df_no_hess)}, removed={len(df) - len(df_no_hess)}')\n",
    "df_no_hess.to_csv(META_NO_HESS, index=False)\n",
    "df_no_hess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3b0521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 37142 files, missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Audio preprocessing is already done in `02.convert_parquet_to_wav.ipynb`\n",
    "# which outputs mono 16 kHz, peak-normalized WAVs into `data_wav/`.\n",
    "# Here we simply verify availability and, if needed, create a pointer table;\n",
    "# no reprocessing or VAD is performed.\n",
    "try:\n",
    "    import torch  # optional: only for potential future steps\n",
    "except ImportError:\n",
    "    torch = None\n",
    "\n",
    "\n",
    "def verify_audio_exists(df):\n",
    "    missing = []\n",
    "    for p in df['audio_wav_path'].tolist():\n",
    "        if not Path(p).exists():\n",
    "            missing.append(p)\n",
    "    print(f\"Checked {len(df)} files, missing: {len(missing)}\")\n",
    "    if missing:\n",
    "        print(\"Examples of missing:\", missing[:5])\n",
    "\n",
    "# Run a quick check (no processing)\n",
    "verify_audio_exists(df_no_hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ed8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared MFA corpus entries: 37142 files at /Volumes/SSanDisk/SpeechRec-German/artifacts/align_input/corpus\n"
     ]
    }
   ],
   "source": [
    "# Populate MFA corpus with symlinks to normalized WAVs\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "ALIGN_CORPUS = ALIGN_INPUT / 'corpus'\n",
    "ALIGN_CORPUS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "META_CLEAN = PROJECT_ROOT / 'data_wav' / 'metadata_wav_clean.csv'\n",
    "META_FALLBACK = PROJECT_ROOT / 'data_wav' / 'metadata_wav.csv'\n",
    "if META_CLEAN.exists():\n",
    "    df_meta = pd.read_csv(META_CLEAN)\n",
    "else:\n",
    "    df_meta = pd.read_csv(META_FALLBACK)\n",
    "    print('Warning: metadata_wav_clean.csv not found, using metadata_wav.csv')\n",
    "\n",
    "USE_SYMLINKS = True  # macOS supports symlinks; set False to copy files\n",
    "\n",
    "created = 0\n",
    "for _, row in df_meta.iterrows():\n",
    "    src_wav = Path(row['audio_wav_path'])\n",
    "    dst_wav = ALIGN_CORPUS / f\"{row['id']}.wav\"\n",
    "    dst_wav.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst_wav.exists():\n",
    "        dst_wav.unlink()\n",
    "    if USE_SYMLINKS:\n",
    "        dst_wav.symlink_to(src_wav)\n",
    "    else:\n",
    "        shutil.copyfile(src_wav, dst_wav)\n",
    "    created += 1\n",
    "\n",
    "print(f'Prepared MFA corpus entries: {created} files at {ALIGN_CORPUS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7214149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...</td>\n",
       "      <td>Man könnte sagen, ich sei für diese Aufgabe pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...</td>\n",
       "      <td>Das heutige vereinte System von Postleitzahlen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...</td>\n",
       "      <td>Eine komplizierte Story mit unzähligen Charakt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...</td>\n",
       "      <td>Siehe weiter unten.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...</td>\n",
       "      <td>Bei niedriger Last werden bis zu vier der acht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...   \n",
       "1  4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...   \n",
       "2  4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...   \n",
       "3  4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...   \n",
       "4  4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...   \n",
       "\n",
       "                                           text_norm  \n",
       "0  Man könnte sagen, ich sei für diese Aufgabe pr...  \n",
       "1  Das heutige vereinte System von Postleitzahlen...  \n",
       "2  Eine komplizierte Story mit unzähligen Charakt...  \n",
       "3                                Siehe weiter unten.  \n",
       "4  Bei niedriger Last werden bis zu vier der acht...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text normalization\n",
    "import re\n",
    "try:\n",
    "    from num2words import num2words\n",
    "except ImportError:\n",
    "    num2words = None\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    t = text.strip()\n",
    "    def repl_digit(match):\n",
    "        num = match.group(0)\n",
    "        if num2words:\n",
    "            return num2words(num, lang='de')\n",
    "        return num  # fallback: keep digits\n",
    "    t = re.sub(r'\\d+', repl_digit, t)\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    return t\n",
    "\n",
    "df_no_hess['text_norm'] = df_no_hess['text'].apply(normalize_text)\n",
    "df_no_hess[['id', 'text_norm']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5afd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>phonemes_ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...</td>\n",
       "      <td>Man könnte sagen, ich sei für diese Aufgabe pr...</td>\n",
       "      <td>man kœntə zɑːɡən ɪç zaɪ fyːɾ diːzə aʊfɡɑːbə pɾ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...</td>\n",
       "      <td>Das heutige vereinte System von Postleitzahlen...</td>\n",
       "      <td>das hɔøtɪɡə fɛɾaɪntə zʏsteːm fɔn pɔstlaɪtsɑːlə...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...</td>\n",
       "      <td>Eine komplizierte Story mit unzähligen Charakt...</td>\n",
       "      <td>aɪnə kɔmpliːtsiːɾtə ʃtoːriː mɪt ʊntsɛːlɪɡən ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...</td>\n",
       "      <td>Siehe weiter unten.</td>\n",
       "      <td>ziːə vaɪtɜ ʊntən</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...</td>\n",
       "      <td>Bei niedriger Last werden bis zu vier der acht...</td>\n",
       "      <td>baɪ niːdɾɪɡɜ last vɛɾdən bɪs tsuː fiːɾ dɛɾ axt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  4aeeae88-0777-2c8c-5c93-2e844a462e49---0e52cfa...   \n",
       "1  4aeeae88-0777-2c8c-5c93-2e844a462e49---2a5f795...   \n",
       "2  4aeeae88-0777-2c8c-5c93-2e844a462e49---6dba565...   \n",
       "3  4aeeae88-0777-2c8c-5c93-2e844a462e49---9d651de...   \n",
       "4  4aeeae88-0777-2c8c-5c93-2e844a462e49---9c33fb6...   \n",
       "\n",
       "                                           text_norm  \\\n",
       "0  Man könnte sagen, ich sei für diese Aufgabe pr...   \n",
       "1  Das heutige vereinte System von Postleitzahlen...   \n",
       "2  Eine komplizierte Story mit unzähligen Charakt...   \n",
       "3                                Siehe weiter unten.   \n",
       "4  Bei niedriger Last werden bis zu vier der acht...   \n",
       "\n",
       "                                        phonemes_ipa  \n",
       "0  man kœntə zɑːɡən ɪç zaɪ fyːɾ diːzə aʊfɡɑːbə pɾ...  \n",
       "1  das hɔøtɪɡə fɛɾaɪntə zʏsteːm fɔn pɔstlaɪtsɑːlə...  \n",
       "2  aɪnə kɔmpliːtsiːɾtə ʃtoːriː mɪt ʊntsɛːlɪɡən ka...  \n",
       "3                                   ziːə vaɪtɜ ʊntən  \n",
       "4  baɪ niːdɾɪɡɜ last vɛɾdən bɪs tsuː fiːɾ dɛɾ axt...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G2P using phonemizer + espeak-ng (de)\n",
    "# Hypotheses:\n",
    "# A: espeak-ng binary missing or not discoverable on PATH\n",
    "# B: German voice data missing/unavailable for espeak-ng\n",
    "# C: Phonemizer binding cannot load espeak-ng library (dylib path issue)\n",
    "\n",
    "# Ensure phonemizer finds the native espeak/espeak-ng library on macOS.\n",
    "import os\n",
    "from pathlib import Path\n",
    "for candidate in [\n",
    "    Path('/opt/homebrew/lib/libespeak-ng.dylib'),\n",
    "    Path('/opt/homebrew/opt/espeak-ng/lib/libespeak-ng.dylib'),\n",
    "    Path('/opt/homebrew/lib/libespeak.dylib'),\n",
    "    Path('/opt/homebrew/opt/espeak/lib/libespeak.dylib'),\n",
    "]:\n",
    "    if candidate.exists():\n",
    "        os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = str(candidate)\n",
    "        dbg_log('A', 'cell6:env', 'Set PHONEMIZER_ESPEAK_LIBRARY', {'runId': RUN_ID, 'path': str(candidate)})\n",
    "        break\n",
    "\n",
    "try:\n",
    "    #region agent log\n",
    "    dbg_log('A', 'cell6:import', 'Attempting to import EspeakBackend', {'runId': RUN_ID})\n",
    "    #endregion\n",
    "    from phonemizer.backend import EspeakBackend\n",
    "    #region agent log\n",
    "    dbg_log('A', 'cell6:is_available', 'EspeakBackend availability check', {'runId': RUN_ID, 'available': EspeakBackend.is_available()})\n",
    "    #endregion\n",
    "    espeak = None\n",
    "    try:\n",
    "        espeak = EspeakBackend(language='de', punctuation_marks=';:,.!?¡¿—…\"\"''“”„”()')\n",
    "        #region agent log\n",
    "        dbg_log('B', 'cell6:init', 'EspeakBackend instantiated', {'runId': RUN_ID, 'voice': 'de'})\n",
    "        #endregion\n",
    "    except RuntimeError as exc:\n",
    "        #region agent log\n",
    "        dbg_log('C', 'cell6:init_error', 'EspeakBackend init failed', {'runId': RUN_ID, 'error': str(exc)})\n",
    "        #endregion\n",
    "        raise\n",
    "except ImportError:\n",
    "    espeak = None\n",
    "    print('phonemizer not installed; install with `pip install phonemizer`')\n",
    "\n",
    "def g2p(text: str) -> str:\n",
    "    if espeak is None:\n",
    "        return ''\n",
    "    return espeak.phonemize([text], strip=True, njobs=1)[0]\n",
    "\n",
    "df_no_hess['phonemes_ipa'] = df_no_hess['text_norm'].apply(g2p)\n",
    "df_no_hess[['id', 'text_norm', 'phonemes_ipa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6e62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Volumes/SSanDisk/SpeechRec-German/data_wav/metadata_wav_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save normalized metadata with G2P\n",
    "META_CLEAN = PROJECT_ROOT / 'data_wav' / 'metadata_wav_clean.csv'\n",
    "df_no_hess.to_csv(META_CLEAN, index=False)\n",
    "print('Saved', META_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6285de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote transcripts to /Volumes/SSanDisk/SpeechRec-German/artifacts/align_input/transcriptions.txt\n",
      "Example MFA CLI:\n",
      "mfa align <corpus_dir> <dictionary> <acoustic_model> <output_dir> --clean --overwrite\n"
     ]
    }
   ],
   "source": [
    "# Prepare MFA input (utterance list and transcriptions)\n",
    "TRANS_TXT = ALIGN_INPUT / 'transcriptions.txt'\n",
    "with open(TRANS_TXT, 'w') as f:\n",
    "    for _, row in df_no_hess.iterrows():\n",
    "        utt_id = row['id']\n",
    "        text = row['text_norm']\n",
    "        f.write(f\"{utt_id} {text}\\n\")\n",
    "print('Wrote transcripts to', TRANS_TXT)\n",
    "\n",
    "# MFA alignment (toggle RUN_MFA to actually run; heavy)\n",
    "import os\n",
    "from shutil import which\n",
    "\n",
    "MFA_CORPUS = ALIGN_INPUT / 'corpus'\n",
    "MFA_DICT = ALIGN_INPUT / 'lexicon.txt'  # set to dictionary path, or use pretrained dict\n",
    "MFA_MODEL = os.environ.get('MFA_MODEL', 'german_mfa')  # replace with actual acoustic model name\n",
    "RUN_MFA = False  # set True to run alignment\n",
    "MFA_JOBS = int(os.environ.get('MFA_JOBS', '4'))\n",
    "\n",
    "MFA_CORPUS.mkdir(parents=True, exist_ok=True)\n",
    "# corpus already populated above with symlinks\n",
    "\n",
    "mfa_bin = os.environ.get('MFA_BIN') or which('mfa')\n",
    "cmd = None\n",
    "if mfa_bin:\n",
    "    cmd = [\n",
    "        mfa_bin,\n",
    "        'align',\n",
    "        str(MFA_CORPUS),\n",
    "        str(MFA_DICT),\n",
    "        str(MFA_MODEL),\n",
    "        str(ALIGN_OUTPUT),\n",
    "        '--clean',\n",
    "        '--overwrite',\n",
    "        '--num_jobs', str(MFA_JOBS),\n",
    "    ]\n",
    "    print('MFA command:', ' '.join(cmd))\n",
    "else:\n",
    "    print('mfa CLI not found; install Montreal Forced Aligner and/or set MFA_BIN')\n",
    "\n",
    "if RUN_MFA and cmd:\n",
    "    dbg_log('A', 'cell_mfa:run', 'Starting MFA alignment', {'cmd': cmd})\n",
    "    result = subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
    "    dbg_log('A', 'cell_mfa:stdout', 'MFA stdout', {'stdout': result.stdout})\n",
    "    dbg_log('A', 'cell_mfa:stderr', 'MFA stderr', {'stderr': result.stderr})\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f'MFA failed with code {result.returncode}')\n",
    "    print('MFA alignment completed.')\n",
    "else:\n",
    "    print('Alignment not executed (set RUN_MFA=True to run).')\n",
    "    print('Example CLI: mfa align <corpus_dir> <dictionary> <acoustic_model> <output_dir> --clean --overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9559a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TextGrid files parsed yet.\n"
     ]
    }
   ],
   "source": [
    "# Parse TextGrid outputs into a phoneme table\n",
    "try:\n",
    "    import textgrid\n",
    "except ImportError:\n",
    "    textgrid = None\n",
    "    print('textgrid not installed; install with `pip install praatio` or `pip install textgrid`.')\n",
    "\n",
    "records = []\n",
    "textgrids = list(ALIGN_OUTPUT.glob('*.TextGrid')) if ALIGN_OUTPUT.exists() else []\n",
    "if textgrid is not None and textgrids:\n",
    "    print(f'Found {len(textgrids)} TextGrid files, parsing...')\n",
    "    for tg_path in textgrids:\n",
    "        utt_id = tg_path.stem\n",
    "        tg = textgrid.TextGrid.fromFile(str(tg_path))\n",
    "        # assume phoneme tier is named 'phones' or 'phonemes'\n",
    "        tier = next((t for t in tg.tiers if t.name.lower() in {'phones', 'phonemes', 'phone', 'phonem'}), None)\n",
    "        if tier is None:\n",
    "            continue\n",
    "        for interval in tier.intervals:\n",
    "            label = interval.mark.strip()\n",
    "            if not label:\n",
    "                continue\n",
    "            records.append({\n",
    "                'utterance_id': utt_id,\n",
    "                'phoneme': label,\n",
    "                'start_ms': interval.minTime * 1000,\n",
    "                'end_ms': interval.maxTime * 1000,\n",
    "                'duration_ms': (interval.maxTime - interval.minTime) * 1000,\n",
    "            })\n",
    "elif textgrid is not None:\n",
    "    print('No TextGrid files found in', ALIGN_OUTPUT)\n",
    "\n",
    "phoneme_df = None\n",
    "if records:\n",
    "    phoneme_df = pd.DataFrame(records)\n",
    "    phoneme_df.to_csv(PHONEME_TBL, index=False)\n",
    "    display(phoneme_df.head())\n",
    "    print('Saved phoneme table to', PHONEME_TBL)\n",
    "else:\n",
    "    print('No TextGrid files parsed yet; run MFA cell first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de260cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: slice phoneme-level audio using ffmpeg\n",
    "def slice_with_ffmpeg(src_wav: Path, start_ms: float, end_ms: float, dst_wav: Path):\n",
    "    duration_ms = max(end_ms - start_ms, 1.0)\n",
    "    cmd = [\n",
    "        'ffmpeg', '-y', '-i', str(src_wav),\n",
    "        '-ac', '1', '-ar', '16000',\n",
    "        '-ss', f'{start_ms/1000:.3f}', '-t', f'{duration_ms/1000:.3f}',\n",
    "        str(dst_wav)\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "def slice_all(phoneme_df: pd.DataFrame, out_root=PHONEME_AUDIO, limit=None):\n",
    "    rows = phoneme_df if limit is None else phoneme_df.head(limit)\n",
    "    for _, row in rows.iterrows():\n",
    "        utt_id = row['utterance_id']\n",
    "        src = AUDIO_OUT / f\"{utt_id}.wav\"\n",
    "        dst = out_root / f\"{utt_id}__{row['phoneme']}__{int(row['start_ms'])}-{int(row['end_ms'])}.wav\"\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        slice_with_ffmpeg(src, row['start_ms'], row['end_ms'], dst)\n",
    "    print(f'Sliced {len(rows)} phoneme clips')\n",
    "\n",
    "# Example usage after alignment is available:\n",
    "# slice_all(phoneme_df, limit=100)  # limit to avoid long run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ca41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick QC: sample a few aligned utterances/phonemes\n",
    "def qc_sample(phoneme_df: pd.DataFrame, n=5):\n",
    "    sample = phoneme_df.sample(n=min(n, len(phoneme_df)), random_state=42)\n",
    "    return sample\n",
    "\n",
    "# Example after alignment\n",
    "# qc_sample(phoneme_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}