{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Hybrid CNN+MLP Training (V3) with Probabilities\n",
    "\n",
    "Training enhanced version of Hybrid CNN+MLP model with probability outputs:\n",
    "- Enhanced CNN: 64→128→256→512 channels with channel attention\n",
    "- Enhanced MLP: 512→512→256→128 neurons\n",
    "- Residual connections with attention in CNN branch\n",
    "- Improved fusion layers: 512+128→512→256→128→64→2\n",
    "- Better training: 100-120 epochs, warmup, cosine annealing, gradient clipping\n",
    "- **Saves probabilities for each phoneme for error analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n",
      "Columns in df_phonemes: ['phoneme_id', 'utterance_id', 'phoneme', 'class', 'start_ms', 'end_ms', 'duration_ms', 'audio_path']\n",
      "Columns in df_features: ['energy_rms', 'energy_rms_std', 'energy_zcr', 'energy_zcr_std', 'spectral_centroid', 'spectral_centroid_std', 'spectral_rolloff', 'spectral_rolloff_std', 'spectral_bandwidth', 'spectral_bandwidth_std', 'formant_f1', 'formant_f2', 'formant_f3', 'formant_f4', 'formant_f1_std', 'formant_f2_std', 'formant_f3_std', 'formant_f4_std', 'spectral_flatness', 'harmonic_noise_ratio', 'zcr_mean', 'energy_cv', 'phoneme_id', 'class', 'duration_ms', 'mfcc_mean_0', 'mfcc_mean_1', 'mfcc_mean_2', 'mfcc_mean_3', 'mfcc_mean_4', 'mfcc_mean_5', 'mfcc_mean_6', 'mfcc_mean_7', 'mfcc_mean_8', 'mfcc_mean_9', 'mfcc_mean_10', 'mfcc_mean_11', 'mfcc_mean_12', 'mfcc_std_0', 'mfcc_std_1', 'mfcc_std_2', 'mfcc_std_3', 'mfcc_std_4', 'mfcc_std_5', 'mfcc_std_6', 'mfcc_std_7', 'mfcc_std_8', 'mfcc_std_9', 'mfcc_std_10', 'mfcc_std_11', 'mfcc_std_12', 'delta_mfcc_mean_0', 'delta_mfcc_mean_1', 'delta_mfcc_mean_2', 'delta_mfcc_mean_3', 'delta_mfcc_mean_4', 'delta_mfcc_mean_5', 'delta_mfcc_mean_6', 'delta_mfcc_mean_7', 'delta_mfcc_mean_8', 'delta_mfcc_mean_9', 'delta_mfcc_mean_10', 'delta_mfcc_mean_11', 'delta_mfcc_mean_12', 'delta_mfcc_std_0', 'delta_mfcc_std_1', 'delta_mfcc_std_2', 'delta_mfcc_std_3', 'delta_mfcc_std_4', 'delta_mfcc_std_5', 'delta_mfcc_std_6', 'delta_mfcc_std_7', 'delta_mfcc_std_8', 'delta_mfcc_std_9', 'delta_mfcc_std_10', 'delta_mfcc_std_11', 'delta_mfcc_std_12', 'delta2_mfcc_mean_0', 'delta2_mfcc_mean_1', 'delta2_mfcc_mean_2', 'delta2_mfcc_mean_3', 'delta2_mfcc_mean_4', 'delta2_mfcc_mean_5', 'delta2_mfcc_mean_6', 'delta2_mfcc_mean_7', 'delta2_mfcc_mean_8', 'delta2_mfcc_mean_9', 'delta2_mfcc_mean_10', 'delta2_mfcc_mean_11', 'delta2_mfcc_mean_12', 'delta2_mfcc_std_0', 'delta2_mfcc_std_1', 'delta2_mfcc_std_2', 'delta2_mfcc_std_3', 'delta2_mfcc_std_4', 'delta2_mfcc_std_5', 'delta2_mfcc_std_6', 'delta2_mfcc_std_7', 'delta2_mfcc_std_8', 'delta2_mfcc_std_9', 'delta2_mfcc_std_10', 'delta2_mfcc_std_11', 'delta2_mfcc_std_12', 'spectral_contrast_mean_0', 'spectral_contrast_mean_1', 'spectral_contrast_mean_2', 'spectral_contrast_mean_3', 'spectral_contrast_mean_4', 'spectral_contrast_mean_5', 'spectral_contrast_mean_6', 'is_outlier_iso', 'quality_score']\n",
      "Columns after merge: ['phoneme_id', 'utterance_id', 'phoneme', 'class_x', 'start_ms', 'end_ms', 'duration_ms_x', 'audio_path', 'energy_rms', 'energy_rms_std', 'energy_zcr', 'energy_zcr_std', 'spectral_centroid', 'spectral_centroid_std', 'spectral_rolloff', 'spectral_rolloff_std', 'spectral_bandwidth', 'spectral_bandwidth_std', 'formant_f1', 'formant_f2', 'formant_f3', 'formant_f4', 'formant_f1_std', 'formant_f2_std', 'formant_f3_std', 'formant_f4_std', 'spectral_flatness', 'harmonic_noise_ratio', 'zcr_mean', 'energy_cv', 'class_y', 'duration_ms_y', 'mfcc_mean_0', 'mfcc_mean_1', 'mfcc_mean_2', 'mfcc_mean_3', 'mfcc_mean_4', 'mfcc_mean_5', 'mfcc_mean_6', 'mfcc_mean_7', 'mfcc_mean_8', 'mfcc_mean_9', 'mfcc_mean_10', 'mfcc_mean_11', 'mfcc_mean_12', 'mfcc_std_0', 'mfcc_std_1', 'mfcc_std_2', 'mfcc_std_3', 'mfcc_std_4', 'mfcc_std_5', 'mfcc_std_6', 'mfcc_std_7', 'mfcc_std_8', 'mfcc_std_9', 'mfcc_std_10', 'mfcc_std_11', 'mfcc_std_12', 'delta_mfcc_mean_0', 'delta_mfcc_mean_1', 'delta_mfcc_mean_2', 'delta_mfcc_mean_3', 'delta_mfcc_mean_4', 'delta_mfcc_mean_5', 'delta_mfcc_mean_6', 'delta_mfcc_mean_7', 'delta_mfcc_mean_8', 'delta_mfcc_mean_9', 'delta_mfcc_mean_10', 'delta_mfcc_mean_11', 'delta_mfcc_mean_12', 'delta_mfcc_std_0', 'delta_mfcc_std_1', 'delta_mfcc_std_2', 'delta_mfcc_std_3', 'delta_mfcc_std_4', 'delta_mfcc_std_5', 'delta_mfcc_std_6', 'delta_mfcc_std_7', 'delta_mfcc_std_8', 'delta_mfcc_std_9', 'delta_mfcc_std_10', 'delta_mfcc_std_11', 'delta_mfcc_std_12', 'delta2_mfcc_mean_0', 'delta2_mfcc_mean_1', 'delta2_mfcc_mean_2', 'delta2_mfcc_mean_3', 'delta2_mfcc_mean_4', 'delta2_mfcc_mean_5', 'delta2_mfcc_mean_6', 'delta2_mfcc_mean_7', 'delta2_mfcc_mean_8', 'delta2_mfcc_mean_9', 'delta2_mfcc_mean_10', 'delta2_mfcc_mean_11', 'delta2_mfcc_mean_12', 'delta2_mfcc_std_0', 'delta2_mfcc_std_1', 'delta2_mfcc_std_2', 'delta2_mfcc_std_3', 'delta2_mfcc_std_4', 'delta2_mfcc_std_5', 'delta2_mfcc_std_6', 'delta2_mfcc_std_7', 'delta2_mfcc_std_8', 'delta2_mfcc_std_9', 'delta2_mfcc_std_10', 'delta2_mfcc_std_11', 'delta2_mfcc_std_12', 'spectral_contrast_mean_0', 'spectral_contrast_mean_1', 'spectral_contrast_mean_2', 'spectral_contrast_mean_3', 'spectral_contrast_mean_4', 'spectral_contrast_mean_5', 'spectral_contrast_mean_6', 'is_outlier_iso', 'quality_score']\n",
      "Warning: Using 'phoneme' column as target instead of 'class'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Determine project root (parent of notebooks directory)\nPROJECT_ROOT = Path.cwd().parent if Path.cwd().name in ['notebooks', 'b-p_first_experiments'] else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.hybrid.hybrid_cnn_mlp_v3 import HybridCNNMLP_V3\n",
    "from utils.training_utils import train_model, evaluate_model, WarmupCosineScheduler, LabelSmoothingCrossEntropy\n",
    "from utils.data_loader import load_data, create_dataloaders\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using MPS device\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "df, spectrograms_dict, feature_cols, feature_scaler, class_weights_dict = load_data(PROJECT_ROOT)\n",
    "dataloaders = create_dataloaders(df, spectrograms_dict, feature_cols, feature_scaler, class_weights_dict, batch_size=64)\n",
    "\n",
    "train_hybrid_loader = dataloaders['hybrid']['train']\n",
    "val_hybrid_loader = dataloaders['hybrid']['val']\n",
    "test_hybrid_loader = dataloaders['hybrid']['test']\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'artifacts' / 'b-p_dl_models' / 'improved_models'\n",
    "class_weights = torch.tensor([class_weights_dict.get('0', class_weights_dict.get(0, 1.0)), \n",
    "                              class_weights_dict.get('1', class_weights_dict.get(1, 1.0))], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Enhanced Hybrid CNN+MLP V3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: HybridCNNMLP_V3\n",
      "Total parameters: 5,857,218\n",
      "Trainable parameters: 5,857,218\n",
      "\n",
      "Training configuration:\n",
      "- Epochs: 100\n",
      "- Warmup epochs: 5\n",
      "- Initial LR: 0.001\n",
      "- Label smoothing: 0.1\n",
      "- Gradient clipping: 1.0\n",
      "- Early stopping patience: 15\n",
      "- Dropout: 0.3\n"
     ]
    }
   ],
   "source": [
    "model = HybridCNNMLP_V3(n_features=len(feature_cols), num_classes=2, dropout=0.3).to(device)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model: {model.get_config()['model_type']}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss function with label smoothing\n",
    "criterion = LabelSmoothingCrossEntropy(smoothing=0.1, weight=class_weights)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler with warmup and cosine annealing\n",
    "num_epochs = 100\n",
    "warmup_epochs = 5\n",
    "scheduler = WarmupCosineScheduler(optimizer, warmup_epochs=warmup_epochs, total_epochs=num_epochs, min_lr=1e-6)\n",
    "\n",
    "save_dir = OUTPUT_DIR / 'hybrid_cnn_mlp_v3'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"- Epochs: {num_epochs}\")\n",
    "print(f\"- Warmup epochs: {warmup_epochs}\")\n",
    "print(f\"- Initial LR: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"- Label smoothing: 0.1\")\n",
    "print(f\"- Gradient clipping: 1.0\")\n",
    "print(f\"- Early stopping patience: 15\")\n",
    "print(f\"- Dropout: 0.3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3987, Train Acc: 0.8976\n",
      "Val Loss: 0.3458, Val Acc: 0.9312\n",
      "Val F1: 0.9318, Val ROC-AUC: 0.9780\n",
      "Learning Rate: 0.000200\n",
      "✓ New best model saved! (F1: 0.9318)\n",
      "\n",
      "Epoch 2/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3473, Train Acc: 0.9262\n",
      "Val Loss: 0.3247, Val Acc: 0.9248\n",
      "Val F1: 0.9264, Val ROC-AUC: 0.9841\n",
      "Learning Rate: 0.000400\n",
      "\n",
      "Epoch 3/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3378, Train Acc: 0.9311\n",
      "Val Loss: 0.3210, Val Acc: 0.9428\n",
      "Val F1: 0.9431, Val ROC-AUC: 0.9844\n",
      "Learning Rate: 0.000600\n",
      "✓ New best model saved! (F1: 0.9431)\n",
      "\n",
      "Epoch 4/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3359, Train Acc: 0.9371\n",
      "Val Loss: 0.3268, Val Acc: 0.9301\n",
      "Val F1: 0.9314, Val ROC-AUC: 0.9849\n",
      "Learning Rate: 0.000800\n",
      "\n",
      "Epoch 5/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3373, Train Acc: 0.9368\n",
      "Val Loss: 0.3216, Val Acc: 0.9426\n",
      "Val F1: 0.9431, Val ROC-AUC: 0.9834\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (F1: 0.9431)\n",
      "\n",
      "Epoch 6/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3378, Train Acc: 0.9362\n",
      "Val Loss: 0.3269, Val Acc: 0.9305\n",
      "Val F1: 0.9315, Val ROC-AUC: 0.9821\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 7/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3291, Train Acc: 0.9406\n",
      "Val Loss: 0.3275, Val Acc: 0.9297\n",
      "Val F1: 0.9309, Val ROC-AUC: 0.9829\n",
      "Learning Rate: 0.000999\n",
      "\n",
      "Epoch 8/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3262, Train Acc: 0.9429\n",
      "Val Loss: 0.3339, Val Acc: 0.9162\n",
      "Val F1: 0.9182, Val ROC-AUC: 0.9847\n",
      "Learning Rate: 0.000998\n",
      "\n",
      "Epoch 9/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3195, Train Acc: 0.9486\n",
      "Val Loss: 0.3301, Val Acc: 0.9231\n",
      "Val F1: 0.9248, Val ROC-AUC: 0.9846\n",
      "Learning Rate: 0.000996\n",
      "\n",
      "Epoch 10/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3163, Train Acc: 0.9501\n",
      "Val Loss: 0.3266, Val Acc: 0.9224\n",
      "Val F1: 0.9241, Val ROC-AUC: 0.9841\n",
      "Learning Rate: 0.000993\n",
      "\n",
      "Epoch 11/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3131, Train Acc: 0.9504\n",
      "Val Loss: 0.3265, Val Acc: 0.9378\n",
      "Val F1: 0.9385, Val ROC-AUC: 0.9838\n",
      "Learning Rate: 0.000990\n",
      "\n",
      "Epoch 12/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3118, Train Acc: 0.9518\n",
      "Val Loss: 0.3644, Val Acc: 0.8879\n",
      "Val F1: 0.8916, Val ROC-AUC: 0.9823\n",
      "Learning Rate: 0.000987\n",
      "\n",
      "Epoch 13/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3089, Train Acc: 0.9548\n",
      "Val Loss: 0.3209, Val Acc: 0.9441\n",
      "Val F1: 0.9444, Val ROC-AUC: 0.9839\n",
      "Learning Rate: 0.000983\n",
      "✓ New best model saved! (F1: 0.9444)\n",
      "\n",
      "Epoch 14/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3044, Train Acc: 0.9578\n",
      "Val Loss: 0.3224, Val Acc: 0.9348\n",
      "Val F1: 0.9359, Val ROC-AUC: 0.9853\n",
      "Learning Rate: 0.000978\n",
      "\n",
      "Epoch 15/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3048, Train Acc: 0.9578\n",
      "Val Loss: 0.3184, Val Acc: 0.9400\n",
      "Val F1: 0.9407, Val ROC-AUC: 0.9841\n",
      "Learning Rate: 0.000973\n",
      "\n",
      "Epoch 16/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2979, Train Acc: 0.9618\n",
      "Val Loss: 0.3312, Val Acc: 0.9284\n",
      "Val F1: 0.9297, Val ROC-AUC: 0.9842\n",
      "Learning Rate: 0.000967\n",
      "\n",
      "Epoch 17/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2989, Train Acc: 0.9612\n",
      "Val Loss: 0.3244, Val Acc: 0.9500\n",
      "Val F1: 0.9501, Val ROC-AUC: 0.9857\n",
      "Learning Rate: 0.000961\n",
      "✓ New best model saved! (F1: 0.9501)\n",
      "\n",
      "Epoch 18/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2953, Train Acc: 0.9637\n",
      "Val Loss: 0.3569, Val Acc: 0.9008\n",
      "Val F1: 0.9037, Val ROC-AUC: 0.9841\n",
      "Learning Rate: 0.000955\n",
      "\n",
      "Epoch 19/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2928, Train Acc: 0.9640\n",
      "Val Loss: 0.3300, Val Acc: 0.9261\n",
      "Val F1: 0.9276, Val ROC-AUC: 0.9834\n",
      "Learning Rate: 0.000947\n",
      "\n",
      "Epoch 20/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2935, Train Acc: 0.9647\n",
      "Val Loss: 0.3269, Val Acc: 0.9466\n",
      "Val F1: 0.9468, Val ROC-AUC: 0.9834\n",
      "Learning Rate: 0.000940\n",
      "\n",
      "Epoch 21/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2888, Train Acc: 0.9682\n",
      "Val Loss: 0.3227, Val Acc: 0.9395\n",
      "Val F1: 0.9401, Val ROC-AUC: 0.9843\n",
      "Learning Rate: 0.000932\n",
      "\n",
      "Epoch 22/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2902, Train Acc: 0.9666\n",
      "Val Loss: 0.3195, Val Acc: 0.9488\n",
      "Val F1: 0.9490, Val ROC-AUC: 0.9849\n",
      "Learning Rate: 0.000923\n",
      "\n",
      "Epoch 23/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2867, Train Acc: 0.9692\n",
      "Val Loss: 0.3221, Val Acc: 0.9516\n",
      "Val F1: 0.9516, Val ROC-AUC: 0.9858\n",
      "Learning Rate: 0.000914\n",
      "✓ New best model saved! (F1: 0.9516)\n",
      "\n",
      "Epoch 24/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2844, Train Acc: 0.9709\n",
      "Val Loss: 0.3221, Val Acc: 0.9492\n",
      "Val F1: 0.9495, Val ROC-AUC: 0.9848\n",
      "Learning Rate: 0.000905\n",
      "\n",
      "Epoch 25/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2842, Train Acc: 0.9712\n",
      "Val Loss: 0.3304, Val Acc: 0.9385\n",
      "Val F1: 0.9392, Val ROC-AUC: 0.9833\n",
      "Learning Rate: 0.000895\n",
      "\n",
      "Epoch 26/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2798, Train Acc: 0.9724\n",
      "Val Loss: 0.3291, Val Acc: 0.9410\n",
      "Val F1: 0.9413, Val ROC-AUC: 0.9836\n",
      "Learning Rate: 0.000884\n",
      "\n",
      "Epoch 27/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2803, Train Acc: 0.9739\n",
      "Val Loss: 0.3300, Val Acc: 0.9509\n",
      "Val F1: 0.9508, Val ROC-AUC: 0.9855\n",
      "Learning Rate: 0.000874\n",
      "\n",
      "Epoch 28/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2751, Train Acc: 0.9761\n",
      "Val Loss: 0.3262, Val Acc: 0.9466\n",
      "Val F1: 0.9468, Val ROC-AUC: 0.9852\n",
      "Learning Rate: 0.000862\n",
      "\n",
      "Epoch 29/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2740, Train Acc: 0.9770\n",
      "Val Loss: 0.3242, Val Acc: 0.9466\n",
      "Val F1: 0.9469, Val ROC-AUC: 0.9843\n",
      "Learning Rate: 0.000851\n",
      "\n",
      "Epoch 30/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2741, Train Acc: 0.9780\n",
      "Val Loss: 0.3360, Val Acc: 0.9344\n",
      "Val F1: 0.9352, Val ROC-AUC: 0.9830\n",
      "Learning Rate: 0.000839\n",
      "\n",
      "Epoch 31/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2719, Train Acc: 0.9782\n",
      "Val Loss: 0.3720, Val Acc: 0.9425\n",
      "Val F1: 0.9417, Val ROC-AUC: 0.9825\n",
      "Learning Rate: 0.000826\n",
      "\n",
      "Epoch 32/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2713, Train Acc: 0.9782\n",
      "Val Loss: 0.3208, Val Acc: 0.9438\n",
      "Val F1: 0.9443, Val ROC-AUC: 0.9851\n",
      "Learning Rate: 0.000814\n",
      "\n",
      "Epoch 33/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2703, Train Acc: 0.9789\n",
      "Val Loss: 0.3292, Val Acc: 0.9460\n",
      "Val F1: 0.9463, Val ROC-AUC: 0.9810\n",
      "Learning Rate: 0.000801\n",
      "\n",
      "Epoch 34/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684, Train Acc: 0.9801\n",
      "Val Loss: 0.3492, Val Acc: 0.9470\n",
      "Val F1: 0.9463, Val ROC-AUC: 0.9833\n",
      "Learning Rate: 0.000787\n",
      "\n",
      "Epoch 35/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2671, Train Acc: 0.9812\n",
      "Val Loss: 0.3295, Val Acc: 0.9455\n",
      "Val F1: 0.9456, Val ROC-AUC: 0.9835\n",
      "Learning Rate: 0.000774\n",
      "\n",
      "Epoch 36/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2647, Train Acc: 0.9828\n",
      "Val Loss: 0.3331, Val Acc: 0.9486\n",
      "Val F1: 0.9488, Val ROC-AUC: 0.9847\n",
      "Learning Rate: 0.000760\n",
      "\n",
      "Epoch 37/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2641, Train Acc: 0.9820\n",
      "Val Loss: 0.3427, Val Acc: 0.9471\n",
      "Val F1: 0.9470, Val ROC-AUC: 0.9759\n",
      "Learning Rate: 0.000745\n",
      "\n",
      "Epoch 38/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2641, Train Acc: 0.9831\n",
      "Val Loss: 0.3327, Val Acc: 0.9425\n",
      "Val F1: 0.9429, Val ROC-AUC: 0.9849\n",
      "Learning Rate: 0.000731\n",
      "\n",
      "Early stopping at epoch 38\n",
      "Best F1: 0.9516 at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Final Test Results:\n",
      "============================================================\n",
      "Accuracy: 0.9469\n",
      "F1-score: 0.9467\n",
      "ROC-AUC: 0.9849\n",
      "Precision: 0.9467\n",
      "Recall: 0.9469\n",
      "Best epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "history, best_epoch = train_model(\n",
    "    model, train_hybrid_loader, val_hybrid_loader, criterion, optimizer, scheduler,\n",
    "    device, num_epochs=num_epochs, save_dir=save_dir, model_name='hybrid_cnn_mlp_v3', \n",
    "    early_stopping_patience=15, max_grad_norm=1.0\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(save_dir / 'best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_metrics, test_preds, test_labels, test_probs = evaluate_model(model, test_hybrid_loader, criterion, device)\n",
    "\n",
    "with open(save_dir / 'test_metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Test Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"Best epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions with Probabilities for Each Phoneme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions with probabilities to: /Volumes/SSanDisk/SpeechRec-German/artifacts/b-p_dl_models/improved_models/hybrid_cnn_mlp_v3/test_predictions_with_probs.csv\n",
      "Total predictions: 5349\n",
      "Correct predictions: 5065\n",
      "Incorrect predictions: 284\n",
      "\n",
      "Summary Statistics:\n",
      "- Average confidence (correct): 0.9152\n",
      "- Average confidence (incorrect): 0.7870\n",
      "- High confidence errors (>0.8): 153\n",
      "- Low confidence errors (<0.6): 36\n"
     ]
    }
   ],
   "source": [
    "# Get test dataset to extract phoneme metadata\n",
    "test_df = df[df['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "# Create predictions dataframe with probabilities\n",
    "predictions_data = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    predictions_data.append({\n",
    "        'phoneme_id': row['phoneme_id'],\n",
    "        'utterance_id': row['utterance_id'],\n",
    "        'phoneme': row['phoneme'],\n",
    "        'true_class': row['class'],\n",
    "        'true_class_encoded': int(test_labels[idx]),\n",
    "        'predicted_class_encoded': int(test_preds[idx]),\n",
    "        'predicted_class': 'b' if test_preds[idx] == 0 else 'p',\n",
    "        'prob_class_0': float(test_probs[idx][0]),  # Probability of class 'b'\n",
    "        'prob_class_1': float(test_probs[idx][1]),  # Probability of class 'p'\n",
    "        'max_prob': float(np.max(test_probs[idx])),\n",
    "        'is_correct': int(test_labels[idx] == test_preds[idx]),\n",
    "        'confidence': float(np.max(test_probs[idx])) if test_labels[idx] == test_preds[idx] else float(test_probs[idx][test_preds[idx]]),\n",
    "        'duration_ms': row.get('duration_ms', None)\n",
    "    })\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_data)\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv(save_dir / 'test_predictions_with_probs.csv', index=False)\n",
    "print(f\"Saved predictions with probabilities to: {save_dir / 'test_predictions_with_probs.csv'}\")\n",
    "print(f\"Total predictions: {len(predictions_df)}\")\n",
    "print(f\"Correct predictions: {predictions_df['is_correct'].sum()}\")\n",
    "print(f\"Incorrect predictions: {(~predictions_df['is_correct'].astype(bool)).sum()}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'total_samples': len(predictions_df),\n",
    "    'correct_predictions': int(predictions_df['is_correct'].sum()),\n",
    "    'incorrect_predictions': int((~predictions_df['is_correct'].astype(bool)).sum()),\n",
    "    'accuracy': float(predictions_df['is_correct'].mean()),\n",
    "    'avg_confidence_correct': float(predictions_df[predictions_df['is_correct'] == 1]['confidence'].mean()),\n",
    "    'avg_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].mean()),\n",
    "    'min_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].min()),\n",
    "    'max_confidence_incorrect': float(predictions_df[predictions_df['is_correct'] == 0]['confidence'].max()),\n",
    "    'high_confidence_errors': int(((predictions_df['is_correct'] == 0) & (predictions_df['confidence'] > 0.8)).sum()),\n",
    "    'low_confidence_errors': int(((predictions_df['is_correct'] == 0) & (predictions_df['confidence'] < 0.6)).sum()),\n",
    "}\n",
    "\n",
    "with open(save_dir / 'predictions_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"- Average confidence (correct): {summary_stats['avg_confidence_correct']:.4f}\")\n",
    "print(f\"- Average confidence (incorrect): {summary_stats['avg_confidence_incorrect']:.4f}\")\n",
    "print(f\"- High confidence errors (>0.8): {summary_stats['high_confidence_errors']}\")\n",
    "print(f\"- Low confidence errors (<0.6): {summary_stats['low_confidence_errors']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions for Validation Set (for analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation predictions to: /Volumes/SSanDisk/SpeechRec-German/artifacts/b-p_dl_models/improved_models/hybrid_cnn_mlp_v3/val_predictions_with_probs.csv\n"
     ]
    }
   ],
   "source": [
    "# Get validation predictions\n",
    "val_metrics, val_preds, val_labels, val_probs = evaluate_model(model, val_hybrid_loader, criterion, device)\n",
    "val_df = df[df['split'] == 'val'].reset_index(drop=True)\n",
    "\n",
    "val_predictions_data = []\n",
    "for idx, row in val_df.iterrows():\n",
    "    val_predictions_data.append({\n",
    "        'phoneme_id': row['phoneme_id'],\n",
    "        'utterance_id': row['utterance_id'],\n",
    "        'phoneme': row['phoneme'],\n",
    "        'true_class': row['class'],\n",
    "        'true_class_encoded': int(val_labels[idx]),\n",
    "        'predicted_class_encoded': int(val_preds[idx]),\n",
    "        'predicted_class': 'b' if val_preds[idx] == 0 else 'p',\n",
    "        'prob_class_0': float(val_probs[idx][0]),\n",
    "        'prob_class_1': float(val_probs[idx][1]),\n",
    "        'max_prob': float(np.max(val_probs[idx])),\n",
    "        'is_correct': int(val_labels[idx] == val_preds[idx]),\n",
    "        'confidence': float(np.max(val_probs[idx])) if val_labels[idx] == val_preds[idx] else float(val_probs[idx][val_preds[idx]]),\n",
    "        'duration_ms': row.get('duration_ms', None)\n",
    "    })\n",
    "\n",
    "val_predictions_df = pd.DataFrame(val_predictions_data)\n",
    "val_predictions_df.to_csv(save_dir / 'val_predictions_with_probs.csv', index=False)\n",
    "print(f\"Saved validation predictions to: {save_dir / 'val_predictions_with_probs.csv'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}