{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models Training\n",
    "\n",
    "Creating Stacking Ensemble from best individual models:\n",
    "- Model 10: Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n",
      "Columns in df_phonemes: ['phoneme_id', 'utterance_id', 'phoneme', 'class', 'start_ms', 'end_ms', 'duration_ms', 'audio_path']\n",
      "Columns in df_features: ['energy_rms', 'energy_rms_std', 'energy_zcr', 'energy_zcr_std', 'spectral_centroid', 'spectral_centroid_std', 'spectral_rolloff', 'spectral_rolloff_std', 'spectral_bandwidth', 'spectral_bandwidth_std', 'formant_f1', 'formant_f2', 'formant_f3', 'formant_f4', 'formant_f1_std', 'formant_f2_std', 'formant_f3_std', 'formant_f4_std', 'spectral_flatness', 'harmonic_noise_ratio', 'zcr_mean', 'energy_cv', 'phoneme_id', 'class', 'duration_ms', 'mfcc_mean_0', 'mfcc_mean_1', 'mfcc_mean_2', 'mfcc_mean_3', 'mfcc_mean_4', 'mfcc_mean_5', 'mfcc_mean_6', 'mfcc_mean_7', 'mfcc_mean_8', 'mfcc_mean_9', 'mfcc_mean_10', 'mfcc_mean_11', 'mfcc_mean_12', 'mfcc_std_0', 'mfcc_std_1', 'mfcc_std_2', 'mfcc_std_3', 'mfcc_std_4', 'mfcc_std_5', 'mfcc_std_6', 'mfcc_std_7', 'mfcc_std_8', 'mfcc_std_9', 'mfcc_std_10', 'mfcc_std_11', 'mfcc_std_12', 'delta_mfcc_mean_0', 'delta_mfcc_mean_1', 'delta_mfcc_mean_2', 'delta_mfcc_mean_3', 'delta_mfcc_mean_4', 'delta_mfcc_mean_5', 'delta_mfcc_mean_6', 'delta_mfcc_mean_7', 'delta_mfcc_mean_8', 'delta_mfcc_mean_9', 'delta_mfcc_mean_10', 'delta_mfcc_mean_11', 'delta_mfcc_mean_12', 'delta_mfcc_std_0', 'delta_mfcc_std_1', 'delta_mfcc_std_2', 'delta_mfcc_std_3', 'delta_mfcc_std_4', 'delta_mfcc_std_5', 'delta_mfcc_std_6', 'delta_mfcc_std_7', 'delta_mfcc_std_8', 'delta_mfcc_std_9', 'delta_mfcc_std_10', 'delta_mfcc_std_11', 'delta_mfcc_std_12', 'delta2_mfcc_mean_0', 'delta2_mfcc_mean_1', 'delta2_mfcc_mean_2', 'delta2_mfcc_mean_3', 'delta2_mfcc_mean_4', 'delta2_mfcc_mean_5', 'delta2_mfcc_mean_6', 'delta2_mfcc_mean_7', 'delta2_mfcc_mean_8', 'delta2_mfcc_mean_9', 'delta2_mfcc_mean_10', 'delta2_mfcc_mean_11', 'delta2_mfcc_mean_12', 'delta2_mfcc_std_0', 'delta2_mfcc_std_1', 'delta2_mfcc_std_2', 'delta2_mfcc_std_3', 'delta2_mfcc_std_4', 'delta2_mfcc_std_5', 'delta2_mfcc_std_6', 'delta2_mfcc_std_7', 'delta2_mfcc_std_8', 'delta2_mfcc_std_9', 'delta2_mfcc_std_10', 'delta2_mfcc_std_11', 'delta2_mfcc_std_12', 'spectral_contrast_mean_0', 'spectral_contrast_mean_1', 'spectral_contrast_mean_2', 'spectral_contrast_mean_3', 'spectral_contrast_mean_4', 'spectral_contrast_mean_5', 'spectral_contrast_mean_6', 'is_outlier_iso', 'quality_score']\n",
      "Columns after merge: ['phoneme_id', 'utterance_id', 'phoneme', 'class_x', 'start_ms', 'end_ms', 'duration_ms_x', 'audio_path', 'energy_rms', 'energy_rms_std', 'energy_zcr', 'energy_zcr_std', 'spectral_centroid', 'spectral_centroid_std', 'spectral_rolloff', 'spectral_rolloff_std', 'spectral_bandwidth', 'spectral_bandwidth_std', 'formant_f1', 'formant_f2', 'formant_f3', 'formant_f4', 'formant_f1_std', 'formant_f2_std', 'formant_f3_std', 'formant_f4_std', 'spectral_flatness', 'harmonic_noise_ratio', 'zcr_mean', 'energy_cv', 'class_y', 'duration_ms_y', 'mfcc_mean_0', 'mfcc_mean_1', 'mfcc_mean_2', 'mfcc_mean_3', 'mfcc_mean_4', 'mfcc_mean_5', 'mfcc_mean_6', 'mfcc_mean_7', 'mfcc_mean_8', 'mfcc_mean_9', 'mfcc_mean_10', 'mfcc_mean_11', 'mfcc_mean_12', 'mfcc_std_0', 'mfcc_std_1', 'mfcc_std_2', 'mfcc_std_3', 'mfcc_std_4', 'mfcc_std_5', 'mfcc_std_6', 'mfcc_std_7', 'mfcc_std_8', 'mfcc_std_9', 'mfcc_std_10', 'mfcc_std_11', 'mfcc_std_12', 'delta_mfcc_mean_0', 'delta_mfcc_mean_1', 'delta_mfcc_mean_2', 'delta_mfcc_mean_3', 'delta_mfcc_mean_4', 'delta_mfcc_mean_5', 'delta_mfcc_mean_6', 'delta_mfcc_mean_7', 'delta_mfcc_mean_8', 'delta_mfcc_mean_9', 'delta_mfcc_mean_10', 'delta_mfcc_mean_11', 'delta_mfcc_mean_12', 'delta_mfcc_std_0', 'delta_mfcc_std_1', 'delta_mfcc_std_2', 'delta_mfcc_std_3', 'delta_mfcc_std_4', 'delta_mfcc_std_5', 'delta_mfcc_std_6', 'delta_mfcc_std_7', 'delta_mfcc_std_8', 'delta_mfcc_std_9', 'delta_mfcc_std_10', 'delta_mfcc_std_11', 'delta_mfcc_std_12', 'delta2_mfcc_mean_0', 'delta2_mfcc_mean_1', 'delta2_mfcc_mean_2', 'delta2_mfcc_mean_3', 'delta2_mfcc_mean_4', 'delta2_mfcc_mean_5', 'delta2_mfcc_mean_6', 'delta2_mfcc_mean_7', 'delta2_mfcc_mean_8', 'delta2_mfcc_mean_9', 'delta2_mfcc_mean_10', 'delta2_mfcc_mean_11', 'delta2_mfcc_mean_12', 'delta2_mfcc_std_0', 'delta2_mfcc_std_1', 'delta2_mfcc_std_2', 'delta2_mfcc_std_3', 'delta2_mfcc_std_4', 'delta2_mfcc_std_5', 'delta2_mfcc_std_6', 'delta2_mfcc_std_7', 'delta2_mfcc_std_8', 'delta2_mfcc_std_9', 'delta2_mfcc_std_10', 'delta2_mfcc_std_11', 'delta2_mfcc_std_12', 'spectral_contrast_mean_0', 'spectral_contrast_mean_1', 'spectral_contrast_mean_2', 'spectral_contrast_mean_3', 'spectral_contrast_mean_4', 'spectral_contrast_mean_5', 'spectral_contrast_mean_6', 'is_outlier_iso', 'quality_score']\n",
      "Warning: Using 'phoneme' column as target instead of 'class'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Determine project root (parent of notebooks directory)\nPROJECT_ROOT = Path.cwd().parent if Path.cwd().name in ['notebooks', 'b-p_first_experiments'] else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.ensemble.stacking_ensemble import StackingEnsemble, EnsemblePredictor\n",
    "from models.spectrogram.resnet_spectrogram import resnet18_spectrogram\n",
    "from models.spectrogram.vit_spectrogram import VisionTransformerSpectrogram\n",
    "from models.hybrid.hybrid_cnn_mlp import HybridCNNMLP\n",
    "from models.hybrid.multimodal_fusion import MultiModalFusion\n",
    "from models.sequence.bilstm_attention import BiLSTMAttention\n",
    "from utils.training_utils import evaluate_model\n",
    "from utils.data_loader import load_data, create_dataloaders\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'artifacts' / 'b-p_dl_models'\n",
    "\n",
    "# Load data\n",
    "df, spectrograms_dict, feature_cols, feature_scaler, class_weights_dict = load_data(PROJECT_ROOT)\n",
    "dataloaders = create_dataloaders(df, spectrograms_dict, feature_cols, feature_scaler, class_weights_dict, batch_size=64)\n",
    "\n",
    "class_weights = torch.tensor([class_weights_dict.get('0', class_weights_dict.get(0, 1.0)), \n",
    "                              class_weights_dict.get('1', class_weights_dict.get(1, 1.0))], dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Models and Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 base models\n"
     ]
    }
   ],
   "source": [
    "# Load all trained models\n",
    "base_models = []\n",
    "model_configs = []\n",
    "\n",
    "# Model 1: ResNet\n",
    "model1 = resnet18_spectrogram(num_classes=2).to(device)\n",
    "checkpoint1 = torch.load(OUTPUT_DIR / 'spectrogram_models' / 'resnet_spectrogram' / 'best_model.pt')\n",
    "model1.load_state_dict(checkpoint1['model_state_dict'])\n",
    "base_models.append(model1)\n",
    "model_configs.append({'name': 'ResNet', 'loader': dataloaders['spectrogram']})\n",
    "\n",
    "# Model 2: ViT\n",
    "model2 = VisionTransformerSpectrogram(img_size=(128, 7), patch_size=(16, 1), embed_dim=128, depth=6, num_heads=8, num_classes=2).to(device)\n",
    "checkpoint2 = torch.load(OUTPUT_DIR / 'spectrogram_models' / 'vit_spectrogram' / 'best_model.pt')\n",
    "model2.load_state_dict(checkpoint2['model_state_dict'])\n",
    "base_models.append(model2)\n",
    "model_configs.append({'name': 'ViT', 'loader': dataloaders['spectrogram']})\n",
    "\n",
    "# Model 3: Hybrid CNN+MLP\n",
    "model3 = HybridCNNMLP(n_features=len(feature_cols), num_classes=2).to(device)\n",
    "checkpoint3 = torch.load(OUTPUT_DIR / 'hybrid_models' / 'hybrid_cnn_mlp' / 'best_model.pt')\n",
    "model3.load_state_dict(checkpoint3['model_state_dict'])\n",
    "base_models.append(model3)\n",
    "model_configs.append({'name': 'Hybrid', 'loader': dataloaders['hybrid']})\n",
    "\n",
    "# Model 5: BiLSTM\n",
    "model5 = BiLSTMAttention(input_dim=128, hidden_dim=64, num_layers=2, num_classes=2).to(device)\n",
    "checkpoint5 = torch.load(OUTPUT_DIR / 'sequence_models' / 'bilstm_attention' / 'best_model.pt')\n",
    "model5.load_state_dict(checkpoint5['model_state_dict'])\n",
    "base_models.append(model5)\n",
    "model_configs.append({'name': 'BiLSTM', 'loader': dataloaders['sequence']})\n",
    "\n",
    "print(f\"Loaded {len(base_models)} base models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training meta-learner...\n",
      "\n",
      "Epoch 1/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1950, Train Acc: 0.9426\n",
      "Val Loss: 0.1406, Val Acc: 0.9552\n",
      "Val F1: 0.9555, Val ROC-AUC: 0.9876\n",
      "✓ New best model saved! (F1: 0.9555)\n",
      "\n",
      "Epoch 2/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1477, Train Acc: 0.9541\n",
      "Val Loss: 0.1370, Val Acc: 0.9531\n",
      "Val F1: 0.9535, Val ROC-AUC: 0.9875\n",
      "\n",
      "Epoch 3/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1459, Train Acc: 0.9520\n",
      "Val Loss: 0.1377, Val Acc: 0.9543\n",
      "Val F1: 0.9547, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 4/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1460, Train Acc: 0.9548\n",
      "Val Loss: 0.1349, Val Acc: 0.9560\n",
      "Val F1: 0.9562, Val ROC-AUC: 0.9878\n",
      "✓ New best model saved! (F1: 0.9562)\n",
      "\n",
      "Epoch 5/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1491, Train Acc: 0.9537\n",
      "Val Loss: 0.1344, Val Acc: 0.9552\n",
      "Val F1: 0.9555, Val ROC-AUC: 0.9878\n",
      "\n",
      "Epoch 6/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1461, Train Acc: 0.9543\n",
      "Val Loss: 0.1342, Val Acc: 0.9543\n",
      "Val F1: 0.9546, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 7/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1455, Train Acc: 0.9537\n",
      "Val Loss: 0.1345, Val Acc: 0.9565\n",
      "Val F1: 0.9568, Val ROC-AUC: 0.9879\n",
      "✓ New best model saved! (F1: 0.9568)\n",
      "\n",
      "Epoch 8/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1430, Train Acc: 0.9545\n",
      "Val Loss: 0.1341, Val Acc: 0.9565\n",
      "Val F1: 0.9568, Val ROC-AUC: 0.9879\n",
      "✓ New best model saved! (F1: 0.9568)\n",
      "\n",
      "Epoch 9/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1419, Train Acc: 0.9539\n",
      "Val Loss: 0.1329, Val Acc: 0.9569\n",
      "Val F1: 0.9572, Val ROC-AUC: 0.9880\n",
      "✓ New best model saved! (F1: 0.9572)\n",
      "\n",
      "Epoch 10/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1444, Train Acc: 0.9545\n",
      "Val Loss: 0.1375, Val Acc: 0.9548\n",
      "Val F1: 0.9552, Val ROC-AUC: 0.9880\n",
      "\n",
      "Epoch 11/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1414, Train Acc: 0.9546\n",
      "Val Loss: 0.1320, Val Acc: 0.9567\n",
      "Val F1: 0.9570, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 12/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451, Train Acc: 0.9518\n",
      "Val Loss: 0.1350, Val Acc: 0.9558\n",
      "Val F1: 0.9561, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 13/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1426, Train Acc: 0.9556\n",
      "Val Loss: 0.1344, Val Acc: 0.9569\n",
      "Val F1: 0.9572, Val ROC-AUC: 0.9879\n",
      "✓ New best model saved! (F1: 0.9572)\n",
      "\n",
      "Epoch 14/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1412, Train Acc: 0.9543\n",
      "Val Loss: 0.1346, Val Acc: 0.9575\n",
      "Val F1: 0.9577, Val ROC-AUC: 0.9879\n",
      "✓ New best model saved! (F1: 0.9577)\n",
      "\n",
      "Epoch 15/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1389, Train Acc: 0.9556\n",
      "Val Loss: 0.1347, Val Acc: 0.9554\n",
      "Val F1: 0.9557, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 16/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1423, Train Acc: 0.9539\n",
      "Val Loss: 0.1320, Val Acc: 0.9567\n",
      "Val F1: 0.9570, Val ROC-AUC: 0.9879\n",
      "\n",
      "Epoch 17/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1470, Train Acc: 0.9569\n",
      "Val Loss: 0.1321, Val Acc: 0.9554\n",
      "Val F1: 0.9557, Val ROC-AUC: 0.9880\n",
      "\n",
      "Epoch 18/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1440, Train Acc: 0.9558\n",
      "Val Loss: 0.1320, Val Acc: 0.9569\n",
      "Val F1: 0.9572, Val ROC-AUC: 0.9881\n",
      "\n",
      "Epoch 19/30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1413, Train Acc: 0.9567\n",
      "Val Loss: 0.1330, Val Acc: 0.9550\n",
      "Val F1: 0.9554, Val ROC-AUC: 0.9881\n",
      "\n",
      "Early stopping at epoch 19\n",
      "Best F1: 0.9577 at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 10 (Stacking Ensemble) Test Results:\n",
      "Accuracy: 0.9467\n",
      "F1: 0.9470\n",
      "ROC-AUC: 0.9879\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from base models on validation set\n",
    "all_val_predictions = []\n",
    "val_labels = None\n",
    "\n",
    "for i, (model, config) in enumerate(zip(base_models, model_configs)):\n",
    "    model.eval()\n",
    "    val_loader = config['loader']['val']\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if isinstance(batch[0], tuple):\n",
    "                inputs = tuple(x.to(device) for x in batch[0])\n",
    "            else:\n",
    "                inputs = batch[0].to(device)\n",
    "            batch_labels = batch[1].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            predictions.append(probs.cpu())\n",
    "            labels.append(batch_labels.cpu())\n",
    "    \n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    all_val_predictions.append(predictions)\n",
    "    if val_labels is None:\n",
    "        val_labels = torch.cat(labels, dim=0)\n",
    "\n",
    "# Stack predictions: (n_samples, n_models * n_classes)\n",
    "stacked_predictions = torch.cat(all_val_predictions, dim=1)\n",
    "\n",
    "# Create dataset for meta-learner\n",
    "meta_dataset = TensorDataset(stacked_predictions, val_labels)\n",
    "meta_loader = DataLoader(meta_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train meta-learner\n",
    "n_base_models = len(base_models)\n",
    "meta_model = StackingEnsemble(n_base_models=n_base_models, n_classes=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(meta_model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "save_dir = OUTPUT_DIR / 'ensemble_models' / 'stacking_ensemble'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Training meta-learner...\")\n",
    "from utils.training_utils import train_model\n",
    "history10, best_epoch10 = train_model(meta_model, meta_loader, meta_loader, criterion, optimizer, scheduler,\n",
    "                                      device, num_epochs=30, save_dir=save_dir, model_name='stacking_ensemble', early_stopping_patience=5)\n",
    "\n",
    "# Evaluate on test set\n",
    "all_test_predictions = []\n",
    "test_labels = None\n",
    "\n",
    "for i, (model, config) in enumerate(zip(base_models, model_configs)):\n",
    "    model.eval()\n",
    "    test_loader = config['loader']['test']\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            if isinstance(batch[0], tuple):\n",
    "                inputs = tuple(x.to(device) for x in batch[0])\n",
    "            else:\n",
    "                inputs = batch[0].to(device)\n",
    "            batch_labels = batch[1].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            predictions.append(probs.cpu())\n",
    "            labels.append(batch_labels.cpu())\n",
    "    \n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    all_test_predictions.append(predictions)\n",
    "    if test_labels is None:\n",
    "        test_labels = torch.cat(labels, dim=0)\n",
    "\n",
    "stacked_test_predictions = torch.cat(all_test_predictions, dim=1)\n",
    "test_dataset = TensorDataset(stacked_test_predictions, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "checkpoint = torch.load(save_dir / 'best_model.pt')\n",
    "meta_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_metrics10, _, _, _ = evaluate_model(meta_model, test_loader, criterion, device)\n",
    "\n",
    "with open(save_dir / 'test_metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics10, f, indent=2)\n",
    "\n",
    "print(f\"\\nModel 10 (Stacking Ensemble) Test Results:\")\n",
    "print(f\"Accuracy: {test_metrics10['accuracy']:.4f}\")\n",
    "print(f\"F1: {test_metrics10['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {test_metrics10['roc_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}