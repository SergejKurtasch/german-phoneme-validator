{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dae89e2b",
      "metadata": {},
      "source": [
        "# Convert Parquet â†’ WAV (16 kHz, mono) per data-prep-plan-ru.md\n",
        "\n",
        "- Source: `Thorsten-Voice/TV-44kHz-Full` (HF streaming).\n",
        "- Output: WAV 16 kHz mono + peak normalization; optional silence trim.\n",
        "- Saves to `data_wav/` and writes updated metadata (CSV/Parquet) with WAV paths.\n",
        "- Idempotent: skips existing WAVs and resumes from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3c5edeab",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q --upgrade datasets soundfile pandas tqdm pyarrow librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4dff2c7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE_DIR /Volumes/SSanDisk/SpeechRec-German\n",
            "SRC_META_CSV exists True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from datasets import Audio, load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Parameters\n",
        "REPO_ID = \"Thorsten-Voice/TV-44kHz-Full\"\n",
        "SPLIT = \"train\"\n",
        "TARGET_SR = 16_000\n",
        "TARGET_PEAK = 0.98  # peak normalize to 98% full scale\n",
        "TRIM_SILENCE = False  # set True to trim leading/trailing silence by simple energy threshold\n",
        "TRIM_THRESHOLD = 0.001  # silence threshold if TRIM_SILENCE=True\n",
        "CHUNK_ROWS = 500  # how often to write metadata and checkpoint\n",
        "\n",
        "BASE_DIR = Path.cwd()\n",
        "SRC_META_CSV = BASE_DIR / \"data_tv_44khz_full\" / \"tv_44khz_full_metadata.csv\"\n",
        "WAV_DIR = BASE_DIR / \"data_wav\"\n",
        "WAV_META_CSV = WAV_DIR / \"tv_44khz_full_metadata_wav.csv\"\n",
        "WAV_META_PARQUET = WAV_DIR / \"tv_44khz_full_metadata_wav.parquet\"\n",
        "CHECKPOINT = WAV_DIR / \"wav_checkpoint.json\"\n",
        "\n",
        "WAV_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"BASE_DIR\", BASE_DIR)\n",
        "print(\"SRC_META_CSV exists\", SRC_META_CSV.exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5033c2fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint helpers\n",
        "def load_checkpoint():\n",
        "    if CHECKPOINT.exists():\n",
        "        try:\n",
        "            return int(json.loads(CHECKPOINT.read_text()).get(\"last_index\", -1))\n",
        "        except Exception:\n",
        "            return -1\n",
        "    return -1\n",
        "\n",
        "def save_checkpoint(last_index: int):\n",
        "    CHECKPOINT.write_text(json.dumps({\"last_index\": int(last_index)}), encoding=\"utf-8\")\n",
        "\n",
        "# Audio transforms\n",
        "def to_mono(audio_np: np.ndarray):\n",
        "    if audio_np.ndim == 1:\n",
        "        return audio_np\n",
        "    return audio_np.mean(axis=0) if audio_np.shape[0] < audio_np.shape[1] else audio_np.mean(axis=1)\n",
        "\n",
        "def normalize_peak(audio_np: np.ndarray, target_peak: float = TARGET_PEAK):\n",
        "    peak = np.max(np.abs(audio_np)) if audio_np.size else 0.0\n",
        "    if peak > 0:\n",
        "        audio_np = audio_np * (target_peak / peak)\n",
        "    return np.clip(audio_np, -1.0, 1.0)\n",
        "\n",
        "def trim_silence(audio_np: np.ndarray, threshold: float = TRIM_THRESHOLD):\n",
        "    if not TRIM_SILENCE or audio_np.size == 0:\n",
        "        return audio_np\n",
        "    abs_sig = np.abs(audio_np)\n",
        "    mask = abs_sig > threshold\n",
        "    if not mask.any():\n",
        "        return audio_np  # all silence, return as-is\n",
        "    idx = np.where(mask)[0]\n",
        "    return audio_np[idx[0]: idx[-1] + 1]\n",
        "\n",
        "def prepare_audio(audio_np: np.ndarray):\n",
        "    mono = to_mono(audio_np)\n",
        "    trimmed = trim_silence(mono)\n",
        "    return normalize_peak(trimmed)\n",
        "\n",
        "# Metadata row builder\n",
        "def meta_row(idx: int, row: dict, wav_path: Path):\n",
        "    m = {\n",
        "        \"idx\": idx,\n",
        "        \"id\": row.get(\"id\"),\n",
        "        \"subset\": row.get(\"subset\"),\n",
        "        \"style\": row.get(\"style\"),\n",
        "        \"text\": row.get(\"text\"),\n",
        "        \"samplerate\": TARGET_SR,\n",
        "        \"durationSeconds\": row.get(\"durationSeconds\"),\n",
        "        \"recording_year_month\": row.get(\"recording_year-month\"),\n",
        "        \"microphone\": row.get(\"microphone\"),\n",
        "        \"language\": row.get(\"language\"),\n",
        "        \"comment\": row.get(\"comment\"),\n",
        "        \"audio_wav_path\": str(wav_path),\n",
        "    }\n",
        "    return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f33154b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from index: 0\n"
          ]
        }
      ],
      "source": [
        "# Determine resume point\n",
        "start_from_cp = load_checkpoint() + 1\n",
        "start_from_meta = 0\n",
        "if WAV_META_CSV.exists():\n",
        "    try:\n",
        "        start_from_meta = sum(1 for _ in open(WAV_META_CSV, \"r\", encoding=\"utf-8\")) - 1  # minus header\n",
        "    except Exception:\n",
        "        start_from_meta = 0\n",
        "start_from = max(start_from_cp, start_from_meta, 0)\n",
        "print(f\"Resuming from index: {start_from}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "93024e1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some datasets params were ignored: ['homepage', 'license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n",
            "parquet->wav: 39248it [16:12, 40.37it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Last index: 39247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Stream dataset audio without auto-decoding (decode=False)\n",
        "ds = load_dataset(REPO_ID, name=\"all\", split=SPLIT, streaming=True)\n",
        "ds = ds.cast_column(\"audio\", Audio(decode=False))\n",
        "\n",
        "buffer = []\n",
        "last_index = start_from - 1\n",
        "progress = tqdm(ds, desc=\"parquet->wav\", initial=start_from)\n",
        "\n",
        "for idx, row in enumerate(progress):\n",
        "    if idx < start_from:\n",
        "        continue\n",
        "\n",
        "    subset = row.get(\"subset\", \"unknown\")\n",
        "    out_path = WAV_DIR / subset / f\"{row['id']}.wav\"\n",
        "    if out_path.exists():\n",
        "        buffer.append(meta_row(idx, row, out_path))\n",
        "    else:\n",
        "        audio_bytes = row[\"audio\"].get(\"bytes\")\n",
        "        if audio_bytes is None:\n",
        "            # if only a path is provided (streaming), read bytes from it\n",
        "            with open(row[\"audio\"][\"path\"], \"rb\") as fh:\n",
        "                audio_bytes = fh.read()\n",
        "        data, sr = sf.read(io.BytesIO(audio_bytes), dtype=\"float32\")\n",
        "        if data.ndim == 1:\n",
        "            audio_arr = data\n",
        "        else:\n",
        "            audio_arr = data.mean(axis=1)\n",
        "        if sr != TARGET_SR:\n",
        "            audio_arr = librosa.resample(audio_arr, orig_sr=sr, target_sr=TARGET_SR)\n",
        "        audio_arr = prepare_audio(np.asarray(audio_arr))\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        sf.write(out_path, audio_arr, TARGET_SR)\n",
        "        buffer.append(meta_row(idx, row, out_path))\n",
        "\n",
        "    last_index = idx\n",
        "    if len(buffer) >= CHUNK_ROWS:\n",
        "        header = not WAV_META_CSV.exists()\n",
        "        pd.DataFrame(buffer).to_csv(WAV_META_CSV, mode=\"a\", header=header, index=False)\n",
        "        buffer.clear()\n",
        "        save_checkpoint(last_index)\n",
        "\n",
        "# final flush\n",
        "if buffer:\n",
        "    header = not WAV_META_CSV.exists()\n",
        "    pd.DataFrame(buffer).to_csv(WAV_META_CSV, mode=\"a\", header=header, index=False)\n",
        "    buffer.clear()\n",
        "\n",
        "save_checkpoint(last_index)\n",
        "print(f\"Done. Last index: {last_index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8e909399",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 39248 rows to /Volumes/SSanDisk/SpeechRec-German/data_wav/tv_44khz_full_metadata_wav.parquet\n",
            "Copied source metadata to /Volumes/SSanDisk/SpeechRec-German/data_wav/tv_44khz_full_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "# Export Parquet and keep a copy of source metadata\n",
        "if WAV_META_CSV.exists():\n",
        "    df = pd.read_csv(WAV_META_CSV)\n",
        "    df.to_parquet(WAV_META_PARQUET, index=False)\n",
        "    print(f\"Wrote {len(df)} rows to {WAV_META_PARQUET}\")\n",
        "\n",
        "# Copy original metadata into data_wav (for comparison)\n",
        "if SRC_META_CSV.exists():\n",
        "    dst = WAV_DIR / SRC_META_CSV.name\n",
        "    if not dst.exists():\n",
        "        dst.write_bytes(SRC_META_CSV.read_bytes())\n",
        "        print(f\"Copied source metadata to {dst}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
